diff --git a/package/kernel/nft-fullcone/Makefile b/package/kernel/nft-fullcone/Makefile
new file mode 100644
index 0000000..f8108a0
--- /dev/null
+++ b/package/kernel/nft-fullcone/Makefile
@@ -0,0 +1,44 @@
+# SPDX-License-Identifier: GPL-2.0-only
+# Copyright (c) 2018 Chion Tang <tech@chionlab.moe>
+#   Original xt_FULLCONENAT and related iptables extension author
+# Copyright (c) 2019-2022 GitHub/llccd Twitter/@gNodeB
+#   Added IPv6 support for xt_FULLCONENAT and ip6tables extension
+#   Ported to recent kernel versions
+# Copyright (c) 2022 Syrone Wong <wong.syrone@gmail.com>
+#   Massively rewrite the whole module, split the original code into library and nftables 'fullcone' expression module
+
+include $(TOPDIR)/rules.mk
+include $(INCLUDE_DIR)/kernel.mk
+
+PKG_NAME:=nft-fullcone
+PKG_RELEASE:=1
+
+include $(INCLUDE_DIR)/package.mk
+
+define KernelPackage/nft-fullcone
+  SUBMENU:=Netfilter Extensions
+  DEPENDS:=@IPV6 +kmod-nft-core +kmod-nf-conntrack +kmod-nf-conntrack6
+  TITLE:=nftables fullcone expression support
+  FILES:= $(PKG_BUILD_DIR)/nft_fullcone.ko
+#  KCONFIG:= CONFIG_NFT_FULLCONE=y CONFIG_NF_NAT=y CONFIG_NF_NAT_IPV6=y CONFIG_NF_CONNTRACK_EVENTS=y CONFIG_NF_CONNTRACK_CHAIN_EVENTS=y
+  PROVIDES:=$(PKG_NAME)
+  AUTOLOAD:=$(call AutoProbe,nft_fullcone)
+endef
+
+define KernelPackage/nft-fullcone/Description
+Kernel module adds the fullcone expression that you can use
+to perform NAT in the RFC3489-compatible full cone SNAT flavour.
+Currently only UDP traffic is supported for full-cone NAT.
+For other protos FULLCONENAT is equivalent to MASQUERADE.
+endef
+
+# make use of all CPUs
+define Build/Compile
+	+$(MAKE) $(PKG_JOBS) $(KERNEL_MAKEOPTS) \
+		M="$(PKG_BUILD_DIR)" \
+		EXTRA_CFLAGS="$(BUILDFLAGS)" \
+		$(if $(CONFIG_IPv6),EXTRA_CFLAGS+="-DCONFIG_SFE_ECM",) \
+		modules
+endef
+
+$(eval $(call KernelPackage,nft-fullcone))
diff --git a/package/kernel/nft-fullcone/src/Makefile b/package/kernel/nft-fullcone/src/Makefile
new file mode 100644
index 0000000..8427ebb
--- /dev/null
+++ b/package/kernel/nft-fullcone/src/Makefile
@@ -0,0 +1,18 @@
+#
+# Makefile for Nftables/netfilter fullcone expression support.
+#
+
+# module name, should not have the same name as src file names
+TARGET = nft_fullcone
+
+obj-m += $(TARGET).o
+
+$(TARGET)-objs := \
+	nf_nat_fullcone.o \
+	nft_ext_fullcone.o
+
+# product
+ccflags-y += -Werror -Wall
+
+# develop
+#ccflags-y += -Wall -Wno-unused-function
diff --git a/package/kernel/nft-fullcone/src/nf_nat_fullcone.c b/package/kernel/nft-fullcone/src/nf_nat_fullcone.c
new file mode 100644
index 0000000..0757ef9
--- /dev/null
+++ b/package/kernel/nft-fullcone/src/nf_nat_fullcone.c
@@ -0,0 +1,1590 @@
+// SPDX-License-Identifier: GPL-2.0-only
+
+/*
+ * Nftables NAT extension: fullcone expression support library
+ *
+ * Copyright (c) 2018 Chion Tang <tech@chionlab.moe>
+ *   Original xt_FULLCONENAT and related iptables extension author
+ * Copyright (c) 2019-2022 GitHub/llccd Twitter/@gNodeB
+ *   Added IPv6 support for xt_FULLCONENAT and ip6tables extension
+ *   Ported to recent kernel versions
+ * Copyright (c) 2022 Syrone Wong <wong.syrone@gmail.com>
+ *   Massively rewrite the whole module, split the original code into library and nftables 'fullcone' expression module
+ */
+
+#define pr_fmt(fmt) "fullcone " KBUILD_MODNAME ": " fmt
+
+#include <linux/version.h>
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/hashtable.h>
+#include <linux/atomic.h>
+#include <linux/kernel.h>
+#include <linux/jhash.h>
+
+#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
+#include <linux/notifier.h>
+#endif
+
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+#include <linux/netfilter_ipv6.h>
+#include <linux/ipv6.h>
+#include <net/addrconf.h>
+#endif
+
+#include "nf_nat_fullcone.h"
+
+/*
+ * FULLCONE_HKEY generates u32 hash value
+ * Modified from net/netfilter/ipset/ip_set_hash_gen.h
+ * dataptr: a pointer
+ * datatypelen: sizeof(struct blah) or sizeof(u32)
+ * initval: initial value
+ * htable_bits: hashtable bits
+ */
+#define FULLCONE_HKEY(dataptr, datatypelen, initval, htable_bits)			\
+({								\
+	const u32 *__k = (const u32 *)(dataptr);			\
+	u32 __l = (datatypelen) / sizeof(u32);			\
+								\
+	BUILD_BUG_ON((datatypelen) % sizeof(u32) != 0);		\
+								\
+	jhash2(__k, __l, (initval)) & jhash_mask((htable_bits));	\
+})
+
+#define HASHTABLE_BUCKET_BITS 10
+
+/* static variables */
+
+static DEFINE_HASHTABLE(mapping_table_by_ext_port, HASHTABLE_BUCKET_BITS);
+static DEFINE_HASHTABLE(mapping_table_by_int_src, HASHTABLE_BUCKET_BITS);
+
+static DEFINE_SPINLOCK(fullconenat_lock);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static DEFINE_HASHTABLE(mapping6_table_by_ext_port, HASHTABLE_BUCKET_BITS);
+static DEFINE_HASHTABLE(mapping6_table_by_int_src, HASHTABLE_BUCKET_BITS);
+
+static DEFINE_SPINLOCK(fullconenat6_lock);
+#endif
+
+static LIST_HEAD(dying_tuple_list);
+static DEFINE_SPINLOCK(dying_tuple_list_lock);
+
+/* static variables end */
+
+/* forward declaration */
+
+#if IS_ENABLED(CONFIG_IPV6)
+static int nat_ipv6_dev_get_saddr(struct net *net, const struct net_device *dev,
+				  const struct in6_addr *daddr, unsigned int srcprefs, struct in6_addr *saddr);
+#endif
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+/* non-atomic: can only be called serially within lock zones. */
+static char *fullcone_nf_ct_stringify_tuple6(const struct nf_conntrack_tuple
+					     *t);
+#endif
+/* non-atomic: can only be called serially within lock zones. */
+static char *nf_ct_stringify_tuple(const struct nf_conntrack_tuple *t);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static struct nat_mapping6 *allocate_mapping6(const union nf_inet_addr
+					      *int_addr,
+					      const uint16_t int_port,
+					      const uint16_t port, const union nf_inet_addr *addr);
+#endif
+static struct nat_mapping *allocate_mapping(const __be32 int_addr,
+					    const uint16_t int_port, const uint16_t port, const __be32 addr);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static void add_original_tuple_to_mapping6(struct nat_mapping6 *mapping, const struct nf_conntrack_tuple
+					   *original_tuple);
+#endif
+static void add_original_tuple_to_mapping(struct nat_mapping *mapping, const struct nf_conntrack_tuple
+					  *original_tuple);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static struct nat_mapping6 *get_mapping6_by_int_src(const union nf_inet_addr
+						    *src_ip, const uint16_t src_port, const union nf_inet_addr
+						    *ext_ip);
+#endif
+
+static struct nat_mapping *get_mapping_by_int_src(const __be32 src_ip, const uint16_t src_port, const __be32 ext_ip);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static struct nat_mapping6 *get_mapping6_by_int_src_inrange(const union
+							    nf_inet_addr
+							    *src_ip, const uint16_t src_port, const union
+							    nf_inet_addr
+							    *min_ip, const union
+							    nf_inet_addr
+							    *max_ip);
+#endif
+static struct nat_mapping *get_mapping_by_int_src_inrange(const __be32 src_ip,
+							  const uint16_t
+							  src_port, const __be32 min_ip, const __be32 max_ip);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static void kill_mapping6(struct nat_mapping6 *mapping);
+#endif
+static void kill_mapping(struct nat_mapping *mapping);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+
+/* check if a mapping is valid.
+ * possibly delete and free an invalid mapping.
+ * the mapping should not be used anymore after check_mapping6() returns 0. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static int check_mapping6(struct nat_mapping6 *mapping, struct net *net, const struct nf_conntrack_zone *zone);
+#else
+static int check_mapping6(struct nat_mapping6 *mapping, struct net *net, const u16 zone);
+#endif
+
+#endif
+
+/* check if a mapping is valid.
+ * possibly delete and free an invalid mapping.
+ * the mapping should not be used anymore after check_mapping() returns 0. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static int check_mapping(struct nat_mapping *mapping, struct net *net, const struct nf_conntrack_zone *zone);
+#else
+static int check_mapping(struct nat_mapping *mapping, struct net *net, const u16 zone);
+#endif
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static struct nat_mapping6 *get_mapping6_by_ext_port(const uint16_t port, const union nf_inet_addr
+						     *ext_ip, struct net *net, const struct
+						     nf_conntrack_zone *zone);
+#else
+static struct nat_mapping6 *get_mapping6_by_ext_port(const uint16_t port, const union nf_inet_addr
+						     *ext_ip, struct net *net, const u16 zone);
+#endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static struct nat_mapping *get_mapping_by_ext_port(const uint16_t port, const __be32 ext_ip, struct net *net, const struct
+						   nf_conntrack_zone *zone);
+#else
+static struct nat_mapping *get_mapping_by_ext_port(const uint16_t port,
+						   const __be32 ext_ip, struct net *net, const u16 zone);
+#endif
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static uint16_t find_appropriate_port6(struct net *net,
+				       const struct nf_conntrack_zone *zone,
+				       const uint16_t original_port, const union nf_inet_addr *ext_ip,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				       struct nf_nat_range2 *range);
+
+#else
+				       struct nf_nat_range *range);
+
+#endif
+
+#else
+static uint16_t find_appropriate_port6(struct net *net, const u16 zone,
+				       const uint16_t original_port, const union nf_inet_addr *ext_ip,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				       struct nf_nat_range2 *range);
+
+#else
+				       struct nf_nat_range *range);
+
+#endif
+#endif
+
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static uint16_t find_appropriate_port(struct net *net,
+				      const struct nf_conntrack_zone *zone,
+				      const uint16_t original_port, const __be32 ext_ip,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				      struct nf_nat_range2 *range);
+#else
+				      struct nf_nat_range *range);
+#endif
+
+#else
+static uint16_t find_appropriate_port(struct net *net, const u16 zone,
+				      const uint16_t original_port, const __be32 ext_ip,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				      struct nf_nat_range2 *range);
+#else
+				      struct nf_nat_range *range);
+#endif
+#endif
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static void find_leastused_ip6(const struct nf_conntrack_zone *zone,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+			       struct nf_nat_range2 *range,
+#else
+			       struct nf_nat_range *range,
+#endif
+			       const union nf_inet_addr *src,
+			       const union nf_inet_addr *dst, union nf_inet_addr *var_ipp);
+#else
+static void find_leastused_ip6(const u16 zone,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+			       struct nf_nat_range2 *range,
+#else
+			       struct nf_nat_range *range,
+#endif
+			       const union nf_inet_addr *src,
+			       const union nf_inet_addr *dst, union nf_inet_addr *var_ipp);
+#endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static __be32 find_leastused_ip(const struct nf_conntrack_zone *zone,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				struct nf_nat_range2 *range,
+#else
+				struct nf_nat_range *range,
+#endif
+				const __be32 src, const __be32 dst);
+#else
+static __be32 find_leastused_ip(const u16 zone,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				struct nf_nat_range2 *range,
+#else
+				struct nf_nat_range *range,
+#endif
+				const __be32 src, const __be32 dst);
+#endif
+
+/* forward declaration end */
+
+/* non-atomic part */
+
+static char tuple_tmp_string[512];
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+/* non-atomic: can only be called serially within lock zones. */
+static char *fullcone_nf_ct_stringify_tuple6(const struct nf_conntrack_tuple *t)
+{
+	snprintf(tuple_tmp_string, sizeof(tuple_tmp_string),
+		 "[%pI6c]:%hu -> [%pI6c]:%hu", &t->src.u3.ip6,
+		 be16_to_cpu(t->src.u.all), &t->dst.u3.ip6, be16_to_cpu(t->dst.u.all));
+	return tuple_tmp_string;
+}
+#endif
+/* non-atomic: can only be called serially within lock zones. */
+static char *nf_ct_stringify_tuple(const struct nf_conntrack_tuple *t)
+{
+	snprintf(tuple_tmp_string, sizeof(tuple_tmp_string),
+		 "%pI4:%hu -> %pI4:%hu", &t->src.u3.ip,
+		 be16_to_cpu(t->src.u.all), &t->dst.u3.ip, be16_to_cpu(t->dst.u.all));
+	return tuple_tmp_string;
+}
+
+/* non-atomic part end */
+
+void nf_nat_fullcone_dying_tuple_list_add(struct list_head *new_dying)
+{
+	spin_lock_bh(&dying_tuple_list_lock);
+	list_add(new_dying, &dying_tuple_list);
+	spin_unlock_bh(&dying_tuple_list_lock);
+}
+
+EXPORT_SYMBOL_GPL(nf_nat_fullcone_dying_tuple_list_add);
+
+void nf_nat_fullcone_handle_dying_tuples(void)
+{
+	struct list_head *iter, *tmp, *iter_2, *tmp_2;
+	struct tuple_list *item;
+	struct nf_conntrack_tuple *ct_tuple;
+	struct nat_mapping *mapping;
+	__be32 ip, ext_ip;
+	uint16_t port;
+	struct nat_mapping_original_tuple *original_tuple_item;
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+	struct nat_mapping6 *mapping6;
+	union nf_inet_addr *ip6, *ext_ip6;
+	spin_lock_bh(&fullconenat6_lock);
+#endif
+
+	spin_lock_bh(&fullconenat_lock);
+	spin_lock_bh(&dying_tuple_list_lock);
+
+	list_for_each_safe(iter, tmp, &dying_tuple_list) {
+		item = list_entry(iter, struct tuple_list, list);
+
+		/* we dont know the conntrack direction for now so we try in both ways. */
+		ct_tuple = &(item->tuple_original);
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+		if (ct_tuple->src.l3num == PF_INET6) {
+			ip6 = &(ct_tuple->src).u3;
+			port = be16_to_cpu((ct_tuple->src).u.udp.port);
+			ext_ip6 = &item->tuple_reply.dst.u3;
+			mapping6 = get_mapping6_by_int_src(ip6, port, ext_ip6);
+			if (mapping6 == NULL) {
+				ext_ip6 = &(ct_tuple->dst).u3;
+				ct_tuple = &(item->tuple_reply);
+				ip6 = &(ct_tuple->src).u3;
+				port = be16_to_cpu((ct_tuple->src).u.udp.port);
+				mapping6 = get_mapping6_by_int_src(ip6, port, ext_ip6);
+				if (mapping6 != NULL) {
+					pr_debug
+					    ("nf_nat_fullcone_handle_dying_tuples(): INBOUND dying conntrack at ext port %d\n",
+					     mapping6->port);
+				}
+			} else {
+				pr_debug
+				    ("nf_nat_fullcone_handle_dying_tuples(): OUTBOUND dying conntrack at ext port %d\n",
+				     mapping6->port);
+			}
+
+			if (mapping6 == NULL) {
+				goto next;
+			}
+
+			/* look for the corresponding out-dated tuple and free it */
+			list_for_each_safe(iter_2, tmp_2, &mapping6->original_tuple_list) {
+				original_tuple_item = list_entry(iter_2, struct
+								 nat_mapping_original_tuple, node);
+
+				if (nf_ct_tuple_equal(&original_tuple_item->tuple, &(item->tuple_original))) {
+					pr_debug
+					    ("nf_nat_fullcone_handle_dying_tuples(): tuple %s expired. free this tuple.\n",
+					     fullcone_nf_ct_stringify_tuple6(&original_tuple_item->tuple));
+					list_del(&original_tuple_item->node);
+					kfree(original_tuple_item);
+					(mapping6->refer_count)--;
+				}
+			}
+
+			/* then kill the mapping if needed */
+			pr_debug
+			    ("nf_nat_fullcone_handle_dying_tuples(): refer_count for mapping at ext_port %d is now %d\n",
+			     mapping6->port, mapping6->refer_count);
+			if (mapping6->refer_count <= 0) {
+				pr_debug
+				    ("nf_nat_fullcone_handle_dying_tuples(): kill expired mapping at ext port %d\n",
+				     mapping6->port);
+				kill_mapping6(mapping6);
+			}
+			goto next;
+		}
+		if (unlikely(ct_tuple->src.l3num != PF_INET))
+#else
+		if (ct_tuple->src.l3num != PF_INET)
+#endif
+			goto next;
+
+		ip = (ct_tuple->src).u3.ip;
+		port = be16_to_cpu((ct_tuple->src).u.udp.port);
+		ext_ip = item->tuple_reply.dst.u3.ip;
+		mapping = get_mapping_by_int_src(ip, port, ext_ip);
+		if (mapping == NULL) {
+			ext_ip = (ct_tuple->dst).u3.ip;
+			ct_tuple = &(item->tuple_reply);
+			ip = (ct_tuple->src).u3.ip;
+			port = be16_to_cpu((ct_tuple->src).u.udp.port);
+			mapping = get_mapping_by_int_src(ip, port, ext_ip);
+			if (mapping != NULL) {
+				pr_debug
+				    ("nf_nat_fullcone_handle_dying_tuples(): INBOUND dying conntrack at ext port %d\n",
+				     mapping->port);
+			}
+		} else {
+			pr_debug
+			    ("nf_nat_fullcone_handle_dying_tuples(): OUTBOUND dying conntrack at ext port %d\n",
+			     mapping->port);
+		}
+
+		if (mapping == NULL) {
+			goto next;
+		}
+
+		/* look for the corresponding out-dated tuple and free it */
+		list_for_each_safe(iter_2, tmp_2, &mapping->original_tuple_list) {
+			original_tuple_item = list_entry(iter_2, struct nat_mapping_original_tuple, node);
+
+			if (nf_ct_tuple_equal(&original_tuple_item->tuple, &(item->tuple_original))) {
+				pr_debug
+				    ("nf_nat_fullcone_handle_dying_tuples(): tuple %s expired. free this tuple.\n",
+				     nf_ct_stringify_tuple(&original_tuple_item->tuple));
+				list_del(&original_tuple_item->node);
+				kfree(original_tuple_item);
+				(mapping->refer_count)--;
+			}
+		}
+
+		/* then kill the mapping if needed */
+		pr_debug
+		    ("nf_nat_fullcone_handle_dying_tuples(): refer_count for mapping at ext_port %d is now %d\n",
+		     mapping->port, mapping->refer_count);
+		if (mapping->refer_count <= 0) {
+			pr_debug
+			    ("nf_nat_fullcone_handle_dying_tuples(): kill expired mapping at ext port %d\n",
+			     mapping->port);
+			kill_mapping(mapping);
+		}
+
+next:
+		list_del(&item->list);
+		kfree(item);
+	}
+
+	spin_unlock_bh(&dying_tuple_list_lock);
+	spin_unlock_bh(&fullconenat_lock);
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+	spin_unlock_bh(&fullconenat6_lock);
+#endif
+}
+
+EXPORT_SYMBOL_GPL(nf_nat_fullcone_handle_dying_tuples);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static struct nat_mapping6 *allocate_mapping6(const union nf_inet_addr
+					      *int_addr,
+					      const uint16_t int_port,
+					      const uint16_t port, const union nf_inet_addr *addr)
+{
+	struct nat_mapping6 *p_new;
+	u32 hash_src;
+
+	p_new = kmalloc(sizeof(struct nat_mapping6), GFP_ATOMIC);
+	if (p_new == NULL) {
+		pr_err("kmalloc() for allocate_mapping6 failed.\n");
+		return NULL;
+	}
+	p_new->addr = *addr;
+	p_new->port = port;
+	p_new->int_addr = *int_addr;
+	p_new->int_port = int_port;
+	p_new->refer_count = 0;
+	(p_new->original_tuple_list).next = &(p_new->original_tuple_list);
+	(p_new->original_tuple_list).prev = &(p_new->original_tuple_list);
+
+	hash_src = FULLCONE_HKEY(int_addr, sizeof(union nf_inet_addr), (u32) int_port, HASHTABLE_BUCKET_BITS);
+	//hash_src = jhash2((u32 *) int_addr->all, 4, (u32) int_port);
+
+	hash_add(mapping6_table_by_ext_port, &p_new->node_by_ext_port, port);
+	hash_add(mapping6_table_by_int_src, &p_new->node_by_int_src, hash_src);
+
+	pr_debug("new mapping allocated for [%pI6c]:%d ==> [%pI6c]:%d\n",
+		 &p_new->int_addr, p_new->int_port, &p_new->addr, p_new->port);
+
+	return p_new;
+}
+#endif
+static struct nat_mapping *allocate_mapping(const __be32 int_addr,
+					    const uint16_t int_port, const uint16_t port, const __be32 addr)
+{
+	struct nat_mapping *p_new;
+	u32 hash_src;
+
+	p_new = kmalloc(sizeof(struct nat_mapping), GFP_ATOMIC);
+	if (p_new == NULL) {
+		pr_err("kmalloc() for allocate_mapping failed.\n");
+		return NULL;
+	}
+	p_new->addr = addr;
+	p_new->port = port;
+	p_new->int_addr = int_addr;
+	p_new->int_port = int_port;
+	p_new->refer_count = 0;
+	(p_new->original_tuple_list).next = &(p_new->original_tuple_list);
+	(p_new->original_tuple_list).prev = &(p_new->original_tuple_list);
+
+	hash_src = FULLCONE_HKEY(&int_addr, sizeof(__be32), (u32) int_port, HASHTABLE_BUCKET_BITS);
+	//hash_src = HASH_2(int_addr, (u32) int_port);
+
+	hash_add(mapping_table_by_ext_port, &p_new->node_by_ext_port, port);
+	hash_add(mapping_table_by_int_src, &p_new->node_by_int_src, hash_src);
+
+	pr_debug("new mapping allocated for %pI4:%d ==> %pI4:%d\n",
+		 &p_new->int_addr, p_new->int_port, &p_new->addr, p_new->port);
+
+	return p_new;
+}
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static void add_original_tuple_to_mapping6(struct nat_mapping6 *mapping, const struct nf_conntrack_tuple
+					   *original_tuple)
+{
+	struct nat_mapping_original_tuple *item = kmalloc(sizeof(struct nat_mapping_original_tuple), GFP_ATOMIC);
+	if (item == NULL) {
+		pr_err("kmalloc() for add_original_tuple_to_mapping6 failed.\n");
+		return;
+	}
+	memcpy(&item->tuple, original_tuple, sizeof(struct nf_conntrack_tuple));
+	list_add(&item->node, &mapping->original_tuple_list);
+	(mapping->refer_count)++;
+}
+#endif
+static void add_original_tuple_to_mapping(struct nat_mapping *mapping, const struct nf_conntrack_tuple
+					  *original_tuple)
+{
+	struct nat_mapping_original_tuple *item = kmalloc(sizeof(struct nat_mapping_original_tuple), GFP_ATOMIC);
+	if (item == NULL) {
+		pr_err("kmalloc() for add_original_tuple_to_mapping failed.\n");
+		return;
+	}
+	memcpy(&item->tuple, original_tuple, sizeof(struct nf_conntrack_tuple));
+	list_add(&item->node, &mapping->original_tuple_list);
+	(mapping->refer_count)++;
+}
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static struct nat_mapping6 *get_mapping6_by_int_src(const union nf_inet_addr
+						    *src_ip, const uint16_t src_port, const union nf_inet_addr
+						    *ext_ip)
+{
+	struct nat_mapping6 *p_current;
+	u32 hash_src = FULLCONE_HKEY(src_ip, sizeof(union nf_inet_addr), (u32) src_port, HASHTABLE_BUCKET_BITS);
+	//u32 hash_src = jhash2((u32 *) src_ip->all, 4, (u32) src_port);
+
+	hash_for_each_possible(mapping6_table_by_int_src, p_current, node_by_int_src, hash_src) {
+		if (nf_inet_addr_cmp(&p_current->int_addr, src_ip)
+		    && p_current->int_port == src_port && nf_inet_addr_cmp(&p_current->addr, ext_ip)) {
+			return p_current;
+		}
+	}
+
+	return NULL;
+}
+#endif
+
+static struct nat_mapping *get_mapping_by_int_src(const __be32 src_ip, const uint16_t src_port, const __be32 ext_ip)
+{
+	struct nat_mapping *p_current;
+	u32 hash_src = FULLCONE_HKEY(&src_ip, sizeof(__be32), (u32) src_port, HASHTABLE_BUCKET_BITS);
+	//u32 hash_src = HASH_2(src_ip, (u32) src_port);
+
+	hash_for_each_possible(mapping_table_by_int_src, p_current, node_by_int_src, hash_src) {
+		if (p_current->int_addr == src_ip && p_current->int_port == src_port && p_current->addr == ext_ip) {
+			return p_current;
+		}
+	}
+
+	return NULL;
+}
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static struct nat_mapping6 *get_mapping6_by_int_src_inrange(const union
+							    nf_inet_addr
+							    *src_ip, const uint16_t src_port, const union
+							    nf_inet_addr
+							    *min_ip, const union
+							    nf_inet_addr
+							    *max_ip)
+{
+	struct nat_mapping6 *p_current;
+
+	u32 hash_src = FULLCONE_HKEY(src_ip, sizeof(union nf_inet_addr), (u32) src_port, HASHTABLE_BUCKET_BITS);
+	//u32 hash_src = jhash2((u32 *) src_ip->all, 4, (u32) src_port);
+
+	hash_for_each_possible(mapping6_table_by_int_src, p_current, node_by_int_src, hash_src) {
+		if (nf_inet_addr_cmp(&p_current->int_addr, src_ip)
+		    && p_current->int_port == src_port
+		    && memcmp(&p_current->addr, min_ip,
+			      sizeof(union nf_inet_addr)) >= 0
+		    && memcmp(&p_current->addr, max_ip, sizeof(union nf_inet_addr)) <= 0) {
+			return p_current;
+		}
+	}
+
+	return NULL;
+}
+#endif
+static struct nat_mapping *get_mapping_by_int_src_inrange(const __be32 src_ip,
+							  const uint16_t
+							  src_port, const __be32 min_ip, const __be32 max_ip)
+{
+	struct nat_mapping *p_current;
+	u32 hash_src = FULLCONE_HKEY(&src_ip, sizeof(__be32), (u32) src_port, HASHTABLE_BUCKET_BITS);
+	//u32 hash_src = HASH_2(src_ip, (u32) src_port);
+
+	hash_for_each_possible(mapping_table_by_int_src, p_current, node_by_int_src, hash_src) {
+		if (p_current->int_addr == src_ip
+		    && p_current->int_port == src_port
+		    && memcmp(&p_current->addr, &min_ip, sizeof(__be32)) >= 0
+		    && memcmp(&p_current->addr, &max_ip, sizeof(__be32)) <= 0) {
+			return p_current;
+		}
+	}
+
+	return NULL;
+}
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+static void kill_mapping6(struct nat_mapping6 *mapping)
+{
+	struct list_head *iter, *tmp;
+	struct nat_mapping_original_tuple *original_tuple_item;
+
+	if (mapping == NULL) {
+		return;
+	}
+
+	list_for_each_safe(iter, tmp, &mapping->original_tuple_list) {
+		original_tuple_item = list_entry(iter, struct nat_mapping_original_tuple, node);
+		list_del(&original_tuple_item->node);
+		kfree(original_tuple_item);
+	}
+
+	hash_del(&mapping->node_by_ext_port);
+	hash_del(&mapping->node_by_int_src);
+	kfree(mapping);
+}
+#endif
+static void kill_mapping(struct nat_mapping *mapping)
+{
+	struct list_head *iter, *tmp;
+	struct nat_mapping_original_tuple *original_tuple_item;
+
+	if (mapping == NULL) {
+		return;
+	}
+
+	list_for_each_safe(iter, tmp, &mapping->original_tuple_list) {
+		original_tuple_item = list_entry(iter, struct nat_mapping_original_tuple, node);
+		list_del(&original_tuple_item->node);
+		kfree(original_tuple_item);
+	}
+
+	hash_del(&mapping->node_by_ext_port);
+	hash_del(&mapping->node_by_int_src);
+	kfree(mapping);
+}
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+
+/* check if a mapping is valid.
+ * possibly delete and free an invalid mapping.
+ * the mapping should not be used anymore after check_mapping6() returns 0. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static int check_mapping6(struct nat_mapping6 *mapping, struct net *net, const struct nf_conntrack_zone *zone)
+{
+#else
+static int check_mapping6(struct nat_mapping6 *mapping, struct net *net, const u16 zone)
+{
+#endif
+	struct list_head *iter, *tmp;
+	struct nat_mapping_original_tuple *original_tuple_item;
+	struct nf_conntrack_tuple_hash *tuple_hash;
+	struct nf_conn *ct;
+
+	/* for dying/unconfirmed conntrack tuples, an IPCT_DESTROY event may NOT be fired.
+	 * so we manually kill one of those tuples once we acquire one. */
+
+	list_for_each_safe(iter, tmp, &mapping->original_tuple_list) {
+		original_tuple_item = list_entry(iter, struct nat_mapping_original_tuple, node);
+
+		tuple_hash = nf_conntrack_find_get(net, zone, &original_tuple_item->tuple);
+
+		if (tuple_hash == NULL) {
+			pr_debug
+			    ("check_mapping6(): tuple %s dying/unconfirmed. free this tuple.\n",
+			     fullcone_nf_ct_stringify_tuple6(&original_tuple_item->tuple));
+
+			list_del(&original_tuple_item->node);
+			kfree(original_tuple_item);
+			(mapping->refer_count)--;
+		} else {
+			ct = nf_ct_tuplehash_to_ctrack(tuple_hash);
+			if (likely(ct != NULL))
+				nf_ct_put(ct);
+		}
+
+	}
+
+	/* kill the mapping if need */
+	pr_debug
+	    ("check_mapping6() refer_count for mapping at ext_port %d is now %d\n",
+	     mapping->port, mapping->refer_count);
+	if (mapping->refer_count <= 0) {
+		pr_debug("check_mapping6(): kill dying/unconfirmed mapping at ext port %d\n", mapping->port);
+		kill_mapping6(mapping);
+		return 0;
+	} else {
+		return 1;
+	}
+}
+
+#endif
+
+/* check if a mapping is valid.
+ * possibly delete and free an invalid mapping.
+ * the mapping should not be used anymore after check_mapping() returns 0. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static int check_mapping(struct nat_mapping *mapping, struct net *net, const struct nf_conntrack_zone *zone)
+{
+#else
+static int check_mapping(struct nat_mapping *mapping, struct net *net, const u16 zone)
+{
+#endif
+	struct list_head *iter, *tmp;
+	struct nat_mapping_original_tuple *original_tuple_item;
+	struct nf_conntrack_tuple_hash *tuple_hash;
+	struct nf_conn *ct;
+
+	/* for dying/unconfirmed conntrack tuples, an IPCT_DESTROY event may NOT be fired.
+	 * so we manually kill one of those tuples once we acquire one. */
+
+	list_for_each_safe(iter, tmp, &mapping->original_tuple_list) {
+		original_tuple_item = list_entry(iter, struct nat_mapping_original_tuple, node);
+
+		tuple_hash = nf_conntrack_find_get(net, zone, &original_tuple_item->tuple);
+
+		if (tuple_hash == NULL) {
+			pr_debug
+			    ("check_mapping(): tuple %s dying/unconfirmed. free this tuple.\n",
+			     nf_ct_stringify_tuple(&original_tuple_item->tuple));
+
+			list_del(&original_tuple_item->node);
+			kfree(original_tuple_item);
+			(mapping->refer_count)--;
+		} else {
+			ct = nf_ct_tuplehash_to_ctrack(tuple_hash);
+			if (likely(ct != NULL))
+				nf_ct_put(ct);
+		}
+
+	}
+
+	/* kill the mapping if need */
+	pr_debug
+	    ("check_mapping() refer_count for mapping at ext_port %d is now %d\n", mapping->port, mapping->refer_count);
+	if (mapping->refer_count <= 0) {
+		pr_debug("check_mapping(): kill dying/unconfirmed mapping at ext port %d\n", mapping->port);
+		kill_mapping(mapping);
+		return 0;
+	} else {
+		return 1;
+	}
+}
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static struct nat_mapping6 *get_mapping6_by_ext_port(const uint16_t port, const union nf_inet_addr
+						     *ext_ip, struct net *net, const struct
+						     nf_conntrack_zone *zone)
+{
+#else
+static struct nat_mapping6 *get_mapping6_by_ext_port(const uint16_t port, const union nf_inet_addr
+						     *ext_ip, struct net *net, const u16 zone)
+{
+#endif
+	struct nat_mapping6 *p_current;
+	struct hlist_node *tmp;
+
+	hash_for_each_possible_safe(mapping6_table_by_ext_port, p_current, tmp, node_by_ext_port, port) {
+		if (p_current->port == port && check_mapping6(p_current, net, zone)
+		    && nf_inet_addr_cmp(&p_current->addr, ext_ip)) {
+			return p_current;
+		}
+	}
+
+	return NULL;
+}
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static struct nat_mapping *get_mapping_by_ext_port(const uint16_t port, const __be32 ext_ip, struct net *net, const struct
+						   nf_conntrack_zone *zone)
+{
+#else
+static struct nat_mapping *get_mapping_by_ext_port(const uint16_t port,
+						   const __be32 ext_ip, struct net *net, const u16 zone)
+{
+#endif
+	struct nat_mapping *p_current;
+	struct hlist_node *tmp;
+
+	hash_for_each_possible_safe(mapping_table_by_ext_port, p_current, tmp, node_by_ext_port, port) {
+		if (p_current->port == port && check_mapping(p_current, net, zone)
+		    && p_current->addr == ext_ip) {
+			return p_current;
+		}
+	}
+
+	return NULL;
+}
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static uint16_t find_appropriate_port6(struct net *net,
+				       const struct nf_conntrack_zone *zone,
+				       const uint16_t original_port, const union nf_inet_addr *ext_ip,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				       struct nf_nat_range2 *range)
+#else
+				       struct nf_nat_range *range)
+#endif
+#else
+static uint16_t find_appropriate_port6(struct net *net, const u16 zone,
+				       const uint16_t original_port, const union nf_inet_addr *ext_ip,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				       struct nf_nat_range2 *range)
+#else
+				       struct nf_nat_range *range)
+#endif
+#endif
+{
+	uint16_t min, start, selected, range_size, i;
+	struct nat_mapping6 *mapping = NULL;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+	// nf_nat_range2 specific
+	memset(&range->base_proto, 0, sizeof(range->base_proto));
+#endif
+	if (range->flags & NF_NAT_RANGE_PROTO_SPECIFIED) {
+		min = be16_to_cpu((range->min_proto).udp.port);
+		range_size = be16_to_cpu((range->max_proto).udp.port) - min + 1;
+	} else {
+		/* minimum port is 1024. same behavior as default linux NAT. */
+		min = 1024;
+		range_size = 65535 - min + 1;
+	}
+
+	if ((range->flags & NF_NAT_RANGE_PROTO_RANDOM)
+	    || (range->flags & NF_NAT_RANGE_PROTO_RANDOM_FULLY)) {
+		/* for now we do the same thing for both --random and --random-fully */
+
+		/* select a random starting point */
+		start = (uint16_t) (prandom_u32() % (u32) range_size);
+	} else {
+
+		if ((original_port >= min && original_port <= min + range_size - 1)
+		    || !(range->flags & NF_NAT_RANGE_PROTO_SPECIFIED)) {
+			/* 1. try to preserve the port if it's available */
+			mapping = get_mapping6_by_ext_port(original_port, ext_ip, net, zone);
+			if (mapping == NULL) {
+				return original_port;
+			}
+		}
+
+		/* otherwise, we start from zero */
+		start = 0;
+	}
+
+	for (i = 0; i < range_size; i++) {
+		/* 2. try to find an available port */
+		selected = min + ((start + i) % range_size);
+		mapping = get_mapping6_by_ext_port(selected, ext_ip, net, zone);
+		if (mapping == NULL) {
+			return selected;
+		}
+	}
+
+	/* 3. at least we tried. override a previous mapping. */
+	selected = min + start;
+	mapping = get_mapping6_by_ext_port(selected, ext_ip, net, zone);
+	kill_mapping6(mapping);
+
+	return selected;
+}
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static uint16_t find_appropriate_port(struct net *net,
+				      const struct nf_conntrack_zone *zone,
+				      const uint16_t original_port, const __be32 ext_ip,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				      struct nf_nat_range2 *range)
+#else
+				      struct nf_nat_range *range)
+#endif
+#else
+static uint16_t find_appropriate_port(struct net *net, const u16 zone,
+				      const uint16_t original_port, const __be32 ext_ip,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				      struct nf_nat_range2 *range)
+#else
+				      struct nf_nat_range *range)
+#endif
+#endif
+{
+	uint16_t min, start, selected, range_size, i;
+	struct nat_mapping *mapping = NULL;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+	// nf_nat_range2 specific
+	memset(&range->base_proto, 0, sizeof(range->base_proto));
+#endif
+	if (range->flags & NF_NAT_RANGE_PROTO_SPECIFIED) {
+		min = be16_to_cpu((range->min_proto).udp.port);
+		range_size = be16_to_cpu((range->max_proto).udp.port) - min + 1;
+	} else {
+		/* minimum port is 1024. same behavior as default linux NAT. */
+		min = 1024;
+		range_size = 65535 - min + 1;
+	}
+
+	if ((range->flags & NF_NAT_RANGE_PROTO_RANDOM)
+	    || (range->flags & NF_NAT_RANGE_PROTO_RANDOM_FULLY)) {
+		/* for now we do the same thing for both --random and --random-fully */
+
+		/* select a random starting point */
+		start = (uint16_t) (prandom_u32() % (u32) range_size);
+	} else {
+
+		if ((original_port >= min && original_port <= min + range_size - 1)
+		    || !(range->flags & NF_NAT_RANGE_PROTO_SPECIFIED)) {
+			/* 1. try to preserve the port if it's available */
+			mapping = get_mapping_by_ext_port(original_port, ext_ip, net, zone);
+			if (mapping == NULL) {
+				return original_port;
+			}
+		}
+
+		/* otherwise, we start from zero */
+		start = 0;
+	}
+
+	for (i = 0; i < range_size; i++) {
+		/* 2. try to find an available port */
+		selected = min + ((start + i) % range_size);
+		mapping = get_mapping_by_ext_port(selected, ext_ip, net, zone);
+		if (mapping == NULL) {
+			return selected;
+		}
+	}
+
+	/* 3. at least we tried. override a previous mapping. */
+	selected = min + start;
+	mapping = get_mapping_by_ext_port(selected, ext_ip, net, zone);
+	kill_mapping(mapping);
+
+	return selected;
+}
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static void find_leastused_ip6(const struct nf_conntrack_zone *zone,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+			       struct nf_nat_range2 *range,
+#else
+			       struct nf_nat_range *range,
+#endif
+			       const union nf_inet_addr *src,
+			       const union nf_inet_addr *dst, union nf_inet_addr *var_ipp)
+#else
+static void find_leastused_ip6(const u16 zone,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+			       struct nf_nat_range2 *range,
+#else
+			       struct nf_nat_range *range,
+#endif
+			       const union nf_inet_addr *src,
+			       const union nf_inet_addr *dst, union nf_inet_addr *var_ipp)
+#endif
+{
+	unsigned int i;
+	/* Host order */
+	u32 minip, maxip, j, dist;
+	bool full_range;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+	// nf_nat_range2 specific
+	memset(&(range->base_proto), 0, sizeof(range->base_proto));
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+	j = FULLCONE_HKEY(src, sizeof(union nf_inet_addr),
+			  range->flags & NF_NAT_RANGE_PERSISTENT ? 0 : dst->all[3] ^ zone->id, HASHTABLE_BUCKET_BITS);
+	//j = jhash2((u32 *) src, 4, range->flags & NF_NAT_RANGE_PERSISTENT ? 0 : dst->all[3] ^ zone->id);
+#else
+	j = FULLCONE_HKEY(src, sizeof(union nf_inet_addr),
+			  range->flags & NF_NAT_RANGE_PERSISTENT ? 0 : dst->all[3] ^ zone, HASHTABLE_BUCKET_BITS);
+	//j = jhash2((u32 *) src, 4, range->flags & NF_NAT_RANGE_PERSISTENT ? 0 : dst->all[3] ^ zone);
+#endif
+
+	full_range = false;
+	for (i = 0; i <= 3; i++) {
+		/* If first bytes of the address are at the maximum, use the
+		 * distance. Otherwise use the full range. */
+		if (!full_range) {
+			minip = ntohl(range->min_addr.all[i]);
+			maxip = ntohl(range->max_addr.all[i]);
+			dist = maxip - minip + 1;
+		} else {
+			minip = 0;
+			dist = ~0;
+		}
+
+		var_ipp->all[i] = (__force __be32) htonl(minip + reciprocal_scale(j, dist));
+		if (var_ipp->all[i] != range->max_addr.all[i])
+			full_range = true;
+
+		if (!(range->flags & NF_NAT_RANGE_PERSISTENT))
+			j ^= (__force u32) dst->all[i];
+	}
+}
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+static __be32 find_leastused_ip(const struct nf_conntrack_zone *zone,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				struct nf_nat_range2 *range,
+#else
+				struct nf_nat_range *range,
+#endif
+				const __be32 src, const __be32 dst)
+#else
+static __be32 find_leastused_ip(const u16 zone,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				struct nf_nat_range2 *range,
+#else
+				struct nf_nat_range *range,
+#endif
+				const __be32 src, const __be32 dst)
+#endif
+{
+	/* Host order */
+	u32 minip, maxip, j, dist;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+	// nf_nat_range2 specific
+	memset(&(range->base_proto), 0, sizeof(range->base_proto));
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+	j = FULLCONE_HKEY(&src, sizeof(__be32), range->flags & NF_NAT_RANGE_PERSISTENT ? 0 : dst ^ zone->id,
+			  HASHTABLE_BUCKET_BITS);
+	//j = jhash_1word((u32) src, range->flags & NF_NAT_RANGE_PERSISTENT ? 0 : dst ^ zone->id);
+#else
+	j = FULLCONE_HKEY(&src, sizeof(__be32), range->flags & NF_NAT_RANGE_PERSISTENT ? 0 : dst ^ zone,
+			  HASHTABLE_BUCKET_BITS);
+	//j = jhash_1word((u32) src, range->flags & NF_NAT_RANGE_PERSISTENT ? 0 : dst ^ zone);
+#endif
+
+	minip = ntohl(range->min_addr.ip);
+	maxip = ntohl(range->max_addr.ip);
+	dist = maxip - minip + 1;
+
+	return (__be32) htonl(minip + reciprocal_scale(j, dist));
+}
+
+void nf_nat_fullcone_destroy_mappings(void)
+{
+	struct nat_mapping *p_current;
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+	struct nat_mapping6 *p6_current;
+#endif
+	struct hlist_node *tmp;
+	int i;
+
+	spin_lock_bh(&fullconenat_lock);
+
+	hash_for_each_safe(mapping_table_by_ext_port, i, tmp, p_current, node_by_ext_port) {
+		kill_mapping(p_current);
+	}
+
+	spin_unlock_bh(&fullconenat_lock);
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+	spin_lock_bh(&fullconenat6_lock);
+
+	hash_for_each_safe(mapping6_table_by_ext_port, i, tmp, p6_current, node_by_ext_port) {
+		kill_mapping6(p6_current);
+	}
+
+	spin_unlock_bh(&fullconenat6_lock);
+#endif
+}
+
+EXPORT_SYMBOL_GPL(nf_nat_fullcone_destroy_mappings);
+
+/*
+ * nfproto choices
+ * enum {
+	NFPROTO_INET   =  1,
+	NFPROTO_IPV4   =  2,
+	NFPROTO_IPV6   = 10,
+};
+ */
+static unsigned int nf_nat_handle_prerouting(u8 nfproto, struct sk_buff *skb, unsigned int hooknum,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+					     struct nf_nat_range2 *newrange)
+#else
+					     struct nf_nat_range *newrange)
+#endif
+{
+	unsigned int ret;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+	const struct nf_conntrack_zone *zone;
+#else
+	u16 zone;
+#endif
+	struct net *net;
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+	struct nf_conntrack_tuple *ct_tuple_origin;
+
+	uint16_t port, original_port;
+	uint8_t protonum;
+
+/* NFPROTO specific def */
+	struct nat_mapping *mapping;
+	struct nat_mapping6 *mapping_6;
+
+	__be32 ip;
+	union nf_inet_addr *ip_6;
+	/* NFPROTO specific def end */
+
+	WARN_ON(!(nfproto == NFPROTO_IPV4 || nfproto == NFPROTO_IPV6));
+
+	/* NFPROTO specific init */
+	mapping = NULL;
+	mapping_6 = NULL;
+
+	ip = 0;
+	ip_6 = NULL;
+	/* NFPROTO specific init end */
+
+	original_port = 0;
+	ret = NFT_CONTINUE;	// BUG: use XT_CONTINUE for Xtables
+
+	ct = nf_ct_get(skb, &ctinfo);
+	net = nf_ct_net(ct);
+	zone = nf_ct_zone(ct);
+
+	ct_tuple_origin = &(ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple);
+
+	protonum = (ct_tuple_origin->dst).protonum;
+	if (protonum != IPPROTO_UDP) {
+		// Currently only UDP traffic is supported for full-cone NAT.
+		// For other protos FULLCONENAT is equivalent to MASQUERADE.
+		return ret;
+	}
+
+	if (nfproto == NFPROTO_IPV4) {
+		ip = (ct_tuple_origin->dst).u3.ip;
+	} else if (nfproto == NFPROTO_IPV6) {
+		ip_6 = &(ct_tuple_origin->dst).u3;
+	}
+
+	port = be16_to_cpu((ct_tuple_origin->dst).u.udp.port);
+
+	if (nfproto == NFPROTO_IPV4) {
+		spin_lock_bh(&fullconenat_lock);
+	} else if (nfproto == NFPROTO_IPV6) {
+		spin_lock_bh(&fullconenat6_lock);
+	}
+
+	/* find an active mapping based on the inbound port */
+	if (nfproto == NFPROTO_IPV4) {
+		mapping = get_mapping_by_ext_port(port, ip, net, zone);
+	} else if (nfproto == NFPROTO_IPV6) {
+		mapping_6 = get_mapping6_by_ext_port(port, ip_6, net, zone);
+	}
+
+	if (nfproto == NFPROTO_IPV4) {
+		if (mapping == NULL) {
+			goto unlock;
+		}
+	} else if (nfproto == NFPROTO_IPV6) {
+		if (mapping_6 == NULL) {
+			goto unlock;
+		}
+	}
+
+	newrange->flags = NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED;
+	if (nfproto == NFPROTO_IPV4) {
+		newrange->min_addr.ip = mapping->int_addr;
+		newrange->max_addr.ip = mapping->int_addr;
+		newrange->min_proto.udp.port = cpu_to_be16(mapping->int_port);
+	} else if (nfproto == NFPROTO_IPV6) {
+		newrange->min_addr = mapping_6->int_addr;
+		newrange->max_addr = mapping_6->int_addr;
+		newrange->min_proto.udp.port = cpu_to_be16(mapping_6->int_port);
+	}
+	newrange->max_proto = newrange->min_proto;
+
+	if (nfproto == NFPROTO_IPV4) {
+		pr_debug("<INBOUND DNAT> %s ==> %pI4:%d\n",
+			 nf_ct_stringify_tuple(ct_tuple_origin), &mapping->int_addr, mapping->int_port);
+	} else if (nfproto == NFPROTO_IPV6) {
+		pr_debug("<INBOUND DNAT> %s ==> [%pI6c]:%d\n",
+			 fullcone_nf_ct_stringify_tuple6(ct_tuple_origin), &mapping_6->int_addr, mapping_6->int_port);
+	}
+
+	ret = nf_nat_setup_info(ct, newrange, HOOK2MANIP(hooknum));
+
+	if (ret == NF_ACCEPT) {
+		if (nfproto == NFPROTO_IPV4) {
+			add_original_tuple_to_mapping(mapping, ct_tuple_origin);
+			pr_debug
+			    ("INBOUND: refer_count for mapping at ext_port %d is now %d\n",
+			     mapping->port, mapping->refer_count);
+		} else if (nfproto == NFPROTO_IPV6) {
+			add_original_tuple_to_mapping6(mapping_6, ct_tuple_origin);
+			pr_debug
+			    ("INBOUND: refer_count for mapping_6 at ext_port %d is now %d\n",
+			     mapping_6->port, mapping_6->refer_count);
+		}
+
+	}
+
+unlock:
+	if (nfproto == NFPROTO_IPV4) {
+		spin_unlock_bh(&fullconenat_lock);
+	} else if (nfproto == NFPROTO_IPV6) {
+		spin_unlock_bh(&fullconenat6_lock);
+	}
+
+	return ret;
+
+}
+
+static unsigned int nf_nat_handle_postrouting(u8 nfproto, struct sk_buff *skb, unsigned int hooknum,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+					      struct nf_nat_range2 *range, struct nf_nat_range2 *newrange,
+#else
+					      struct nf_nat_range *range, struct nf_nat_range *newrange,
+#endif
+					      const struct net_device *out)
+{
+	unsigned int ret;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)
+	const struct nf_conntrack_zone *zone;
+#else
+	u16 zone;
+#endif
+	struct net *net;
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+	struct nf_conn_nat *nat;
+	struct nf_conntrack_tuple *ct_tuple, *ct_tuple_origin;
+	uint16_t port, original_port, want_port;
+	uint8_t protonum;
+	bool is_src_mapping_active;
+
+	/* NFPROTO specific def */
+	struct nat_mapping *mapping, *src_mapping;
+	struct nat_mapping6 *mapping_6, *src_mapping_6;
+
+	__be32 ip;
+	union nf_inet_addr *ip_6;
+
+	const struct rtable *rt;
+	__be32 newsrc, nh;
+
+	/* NFPROTO specific def end */
+
+	WARN_ON(!(nfproto == NFPROTO_IPV4 || nfproto == NFPROTO_IPV6));
+
+	/* NFPROTO specific init */
+	mapping = NULL;
+	src_mapping = NULL;
+	mapping_6 = NULL;
+	src_mapping_6 = NULL;
+
+	ip = 0;
+	ip_6 = NULL;
+	/* NFPROTO specific init end */
+
+	original_port = 0;
+	ret = NFT_CONTINUE;	// BUG: use XT_CONTINUE for Xtables
+
+	ct = nf_ct_get(skb, &ctinfo);
+	net = nf_ct_net(ct);
+	zone = nf_ct_zone(ct);
+
+	ct_tuple_origin = &(ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple);
+	protonum = (ct_tuple_origin->dst).protonum;
+
+	if (range->flags & NF_NAT_RANGE_MAP_IPS) {
+		if (nfproto == NFPROTO_IPV4) {
+			newrange->min_addr.ip = range->min_addr.ip;
+			newrange->max_addr.ip = range->max_addr.ip;
+		} else if (nfproto == NFPROTO_IPV6) {
+			newrange->min_addr = range->min_addr;
+			newrange->max_addr = range->max_addr;
+		}
+
+	} else {
+		if (nfproto == NFPROTO_IPV4) {
+			rt = skb_rtable(skb);
+			nh = rt_nexthop(rt, ip_hdr(skb)->daddr);
+			newsrc = inet_select_addr(out, nh, RT_SCOPE_UNIVERSE);
+
+			if (unlikely(!newsrc))
+				return NF_DROP;
+			newrange->min_addr.ip = newsrc;
+			newrange->max_addr.ip = newsrc;
+		} else if (nfproto == NFPROTO_IPV6) {
+			if (unlikely
+			    (nat_ipv6_dev_get_saddr
+			     (nf_ct_net(ct), out, &ipv6_hdr(skb)->daddr, 0, &(newrange->min_addr.in6)) < 0))
+				return NF_DROP;
+			newrange->max_addr = newrange->min_addr;
+
+		}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
+		nat = nf_ct_nat_ext_add(ct);
+#else
+		nat = nfct_nat(ct);
+#endif
+		if (likely(nat))
+			nat->masq_index = out->ifindex;
+
+	}
+
+	if (protonum == IPPROTO_UDP) {
+		if (nfproto == NFPROTO_IPV4) {
+			ip = (ct_tuple_origin->src).u3.ip;
+		} else if (nfproto == NFPROTO_IPV6) {
+			ip_6 = &(ct_tuple_origin->src).u3;
+		}
+
+		original_port = be16_to_cpu((ct_tuple_origin->src).u.udp.port);
+
+		if (nfproto == NFPROTO_IPV4) {
+			spin_lock_bh(&fullconenat_lock);
+		} else if (nfproto == NFPROTO_IPV6) {
+			spin_lock_bh(&fullconenat6_lock);
+		}
+
+		if (nfproto == NFPROTO_IPV4) {
+			if (newrange->min_addr.ip != newrange->max_addr.ip)
+				src_mapping =
+				    get_mapping_by_int_src_inrange(ip,
+								   original_port,
+								   newrange->min_addr.ip, newrange->max_addr.ip);
+			else
+				src_mapping = get_mapping_by_int_src(ip, original_port, newrange->min_addr.ip);
+		} else if (nfproto == NFPROTO_IPV6) {
+			if (!nf_inet_addr_cmp(&newrange->min_addr, &newrange->max_addr))
+				src_mapping_6 =
+				    get_mapping6_by_int_src_inrange(ip_6,
+								    original_port,
+								    &newrange->min_addr, &newrange->max_addr);
+			else
+				src_mapping_6 = get_mapping6_by_int_src(ip_6, original_port, &newrange->min_addr);
+		}
+
+		if (nfproto == NFPROTO_IPV4) {
+			is_src_mapping_active = src_mapping != NULL && check_mapping(src_mapping, net, zone);
+		} else if (nfproto == NFPROTO_IPV6) {
+			is_src_mapping_active = src_mapping_6 != NULL && check_mapping6(src_mapping_6, net, zone);
+		}
+
+		if (is_src_mapping_active) {
+
+			/* outbound nat: if a previously established mapping is active,
+			 * we will reuse that mapping. */
+
+			newrange->flags = NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED;
+			if (nfproto == NFPROTO_IPV4) {
+				newrange->min_proto.udp.port = cpu_to_be16(src_mapping->port);
+			} else if (nfproto == NFPROTO_IPV6) {
+				newrange->min_proto.udp.port = cpu_to_be16(src_mapping_6->port);
+			}
+
+			newrange->max_proto = newrange->min_proto;
+
+			if (nfproto == NFPROTO_IPV4) {
+				if (newrange->min_addr.ip != newrange->max_addr.ip) {
+					newrange->min_addr.ip = src_mapping->addr;
+					newrange->max_addr.ip = newrange->min_addr.ip;
+				}
+			} else if (nfproto == NFPROTO_IPV6) {
+				if (!nf_inet_addr_cmp(&newrange->min_addr, &newrange->max_addr)) {
+					newrange->min_addr = src_mapping_6->addr;
+					newrange->max_addr = newrange->min_addr;
+				}
+			}
+
+		} else {
+
+			/* if not, we find a new external IP:port to map to.
+			 * the SNAT may fail so we should re-check the mapped port later. */
+
+			if (nfproto == NFPROTO_IPV4) {
+				if (newrange->min_addr.ip != newrange->max_addr.ip) {
+					newrange->min_addr.ip =
+					    find_leastused_ip(zone, range, ip, (ct_tuple_origin->dst).u3.ip);
+					newrange->max_addr.ip = newrange->min_addr.ip;
+				}
+				want_port =
+				    find_appropriate_port(net, zone, original_port, newrange->min_addr.ip, range);
+			} else if (nfproto == NFPROTO_IPV6) {
+
+				if (!nf_inet_addr_cmp(&newrange->min_addr, &newrange->max_addr)) {
+					find_leastused_ip6(zone, range, ip_6,
+							   &(ct_tuple_origin->dst).u3, &newrange->min_addr);
+					newrange->max_addr = newrange->min_addr;
+				}
+
+				want_port =
+				    find_appropriate_port6(net, zone, original_port, &newrange->min_addr, range);
+			}
+
+			newrange->flags = NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED;
+			newrange->min_proto.udp.port = cpu_to_be16(want_port);
+			newrange->max_proto = newrange->min_proto;
+
+			if (nfproto == NFPROTO_IPV4) {
+				src_mapping = NULL;
+			} else if (nfproto == NFPROTO_IPV6) {
+				src_mapping_6 = NULL;
+			}
+
+		}
+	}
+
+	/* do SNAT now */
+	ret = nf_nat_setup_info(ct, newrange, HOOK2MANIP(hooknum));
+
+	if (protonum != IPPROTO_UDP) {
+		/* non-UDP packets, bailout */
+		goto out;
+	}
+	if (ret != NF_ACCEPT) {
+		/* failed SNAT, bailout */
+		goto unlock;
+	}
+
+	/* the reply tuple contains the mapped port. */
+	ct_tuple = &(ct->tuplehash[IP_CT_DIR_REPLY].tuple);
+	/* this is the resulted mapped port. */
+	port = be16_to_cpu((ct_tuple->dst).u.udp.port);
+
+	if (nfproto == NFPROTO_IPV4) {
+		pr_debug("<OUTBOUND SNAT> %s ==> %d\n", nf_ct_stringify_tuple(ct_tuple_origin), port);
+	} else if (nfproto == NFPROTO_IPV6) {
+		pr_debug("<OUTBOUND SNAT> %s ==> %d\n", fullcone_nf_ct_stringify_tuple6(ct_tuple_origin), port);
+	}
+
+	/* save the mapping information into our mapping table */
+
+	if (nfproto == NFPROTO_IPV4) {
+		mapping = src_mapping;
+		if (mapping == NULL) {
+			mapping = allocate_mapping(ip, original_port, port, (ct_tuple->dst).u3.ip);
+		}
+		if (likely(mapping != NULL)) {
+			add_original_tuple_to_mapping(mapping, ct_tuple_origin);
+			pr_debug
+			    (" OUTBOUND: refer_count for mapping at ext_port %d is now %d\n",
+			     mapping->port, mapping->refer_count);
+		}
+	} else if (nfproto == NFPROTO_IPV6) {
+		mapping_6 = src_mapping_6;
+		if (mapping_6 == NULL) {
+			mapping_6 = allocate_mapping6(ip_6, original_port, port, &(ct_tuple->dst).u3);
+		}
+		if (likely(mapping_6 != NULL)) {
+			add_original_tuple_to_mapping6(mapping_6, ct_tuple_origin);
+			pr_debug
+			    ("OUTBOUND: refer_count for mapping at ext_port %d is now %d\n",
+			     mapping_6->port, mapping_6->refer_count);
+		}
+	}
+
+unlock:
+	if (nfproto == NFPROTO_IPV4) {
+		spin_unlock_bh(&fullconenat_lock);
+	} else if (nfproto == NFPROTO_IPV6) {
+		spin_unlock_bh(&fullconenat6_lock);
+	}
+
+out:
+	return ret;
+}
+
+unsigned int nf_nat_fullcone_ipv4(struct sk_buff *skb, unsigned int hooknum,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				  struct nf_nat_range2 *range,
+#else
+				  struct nf_nat_range *range,
+#endif
+				  const struct net_device *out)
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+	struct nf_nat_range2 newrange;
+#else
+	struct nf_nat_range newrange;
+#endif
+
+	WARN_ON(!(hooknum == NF_INET_POST_ROUTING || hooknum == NF_INET_PRE_ROUTING));
+
+	memset(&newrange.min_addr, 0, sizeof(newrange.min_addr));
+	memset(&newrange.max_addr, 0, sizeof(newrange.max_addr));
+	newrange.flags = range->flags | NF_NAT_RANGE_MAP_IPS;
+	newrange.min_proto = range->min_proto;
+	newrange.max_proto = range->max_proto;
+
+	switch (hooknum) {
+	case NF_INET_PRE_ROUTING:
+		/* inbound packets */
+		return nf_nat_handle_prerouting(NFPROTO_IPV4, skb, hooknum, &newrange);
+	case NF_INET_POST_ROUTING:
+		/* outbound packets */
+		return nf_nat_handle_postrouting(NFPROTO_IPV4, skb, hooknum, range, &newrange, out);
+	}
+
+	WARN_ON(1);
+	// logical error
+	return 5;
+}
+
+EXPORT_SYMBOL_GPL(nf_nat_fullcone_ipv4);
+
+#if IS_ENABLED(CONFIG_IPV6)
+static int
+nat_ipv6_dev_get_saddr(struct net *net, const struct net_device *dev,
+		       const struct in6_addr *daddr, unsigned int srcprefs, struct in6_addr *saddr)
+{
+#ifdef CONFIG_IPV6_MODULE
+	const struct nf_ipv6_ops *v6_ops = nf_get_ipv6_ops();
+
+	if (!v6_ops)
+		return -EHOSTUNREACH;
+
+	return v6_ops->dev_get_saddr(net, dev, daddr, srcprefs, saddr);
+#else
+	return ipv6_dev_get_saddr(net, dev, daddr, srcprefs, saddr);
+#endif
+}
+#endif
+
+unsigned int nf_nat_fullcone_ipv6(struct sk_buff *skb, unsigned int hooknum,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				  struct nf_nat_range2 *range,
+#else
+				  struct nf_nat_range *range,
+#endif
+				  const struct net_device *out)
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+	struct nf_nat_range2 newrange;
+#else
+	struct nf_nat_range newrange;
+#endif
+
+	WARN_ON(!(hooknum == NF_INET_POST_ROUTING || hooknum == NF_INET_PRE_ROUTING));
+
+	memset(&newrange.min_addr, 0, sizeof(newrange.min_addr));
+	memset(&newrange.max_addr, 0, sizeof(newrange.max_addr));
+	newrange.flags = range->flags | NF_NAT_RANGE_MAP_IPS;
+	newrange.min_proto = range->min_proto;
+	newrange.max_proto = range->max_proto;
+
+	switch (hooknum) {
+	case NF_INET_PRE_ROUTING:
+		/* inbound packets */
+		return nf_nat_handle_prerouting(NFPROTO_IPV6, skb, hooknum, &newrange);
+	case NF_INET_POST_ROUTING:
+		/* outbound packets */
+		return nf_nat_handle_postrouting(NFPROTO_IPV6, skb, hooknum, range, &newrange, out);
+	}
+
+	WARN_ON(1);
+	// logical error
+	return 5;
+}
+
+EXPORT_SYMBOL_GPL(nf_nat_fullcone_ipv6);
diff --git a/package/kernel/nft-fullcone/src/nf_nat_fullcone.h b/package/kernel/nft-fullcone/src/nf_nat_fullcone.h
new file mode 100644
index 0000000..289ce5c
--- /dev/null
+++ b/package/kernel/nft-fullcone/src/nf_nat_fullcone.h
@@ -0,0 +1,156 @@
+// SPDX-License-Identifier: GPL-2.0-only
+
+/*
+ * Nftables NAT extension: fullcone expression support library header
+ *
+ * Copyright (c) 2018 Chion Tang <tech@chionlab.moe>
+ *   Original xt_FULLCONENAT and related iptables extension author
+ * Copyright (c) 2019-2022 GitHub/llccd Twitter/@gNodeB
+ *   Added IPv6 support for xt_FULLCONENAT and ip6tables extension
+ *   Ported to recent kernel versions
+ * Copyright (c) 2022 Syrone Wong <wong.syrone@gmail.com>
+ *   Massively rewrite the whole module, split the original code into library and nftables 'fullcone' expression module
+ */
+#ifndef _NF_NAT_FULLCONE_H_
+#define _NF_NAT_FULLCONE_H_
+
+#include <linux/version.h>
+#include <linux/skbuff.h>
+#include <linux/list.h>
+#include <linux/inetdevice.h>
+#include <linux/netfilter/nf_tables.h>
+
+#include <net/netfilter/nf_nat.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_zones.h>
+#include <net/netfilter/nf_conntrack_tuple.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <net/netfilter/nf_conntrack_ecache.h>
+
+#ifndef NF_NAT_RANGE_PROTO_RANDOM_FULLY
+#define NF_NAT_RANGE_PROTO_RANDOM_FULLY (1 << 4)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 10, 0)
+static inline int nf_ct_netns_get(struct net *net, u8 nfproto)
+{
+	return 0;
+}
+
+static inline void nf_ct_netns_put(struct net *net, u8 nfproto)
+{
+}
+#endif
+
+/**
+ * enum nft_fullcone_attributes - nf_tables fullcone expression netlink attributes
+ *
+ * @NFTA_FULLCONE_REG_PROTO_MIN: source register of proto range start (NLA_U32: nft_registers)
+ * @NFTA_FULLCONE_REG_PROTO_MAX: source register of proto range end (NLA_U32: nft_registers)
+ * @NFTA_FULLCONE_FLAGS: NAT flags (see NF_NAT_RANGE_* in linux/netfilter/nf_nat.h) (NLA_U32)
+ */
+enum nft_fullcone_attributes {
+	NFTA_FULLCONE_UNSPEC,
+	NFTA_FULLCONE_REG_PROTO_MIN,
+	NFTA_FULLCONE_REG_PROTO_MAX,
+	NFTA_FULLCONE_FLAGS,
+	__NFTA_FULLCONE_MAX
+};
+#define NFTA_FULLCONE_MAX		(__NFTA_FULLCONE_MAX - 1)
+
+/* fullcone specific data structures */
+
+struct nat_mapping_original_tuple {
+	struct nf_conntrack_tuple tuple;
+
+	struct list_head node;
+};
+
+struct nat_mapping {
+	uint16_t port;		/* external source port */
+	__be32 addr;		/* external source ip address */
+
+	__be32 int_addr;	/* internal source ip address */
+	uint16_t int_port;	/* internal source port */
+
+	int refer_count;	/* how many references linked to this mapping
+				 * aka. length of original_tuple_list */
+
+	struct list_head original_tuple_list;
+
+	struct hlist_node node_by_ext_port;
+	struct hlist_node node_by_int_src;
+
+};
+
+#if IS_ENABLED(CONFIG_NF_NAT_IPV6) || (IS_ENABLED(CONFIG_IPV6) && LINUX_VERSION_CODE >= KERNEL_VERSION(5, 1, 0))
+struct nat_mapping6 {
+	uint16_t port;		/* external source port */
+	union nf_inet_addr addr;	/* external source ip address */
+
+	union nf_inet_addr int_addr;	/* internal source ip address */
+	uint16_t int_port;	/* internal source port */
+
+	int refer_count;	/* how many references linked to this mapping
+				 * aka. length of original_tuple_list */
+
+	struct list_head original_tuple_list;
+
+	struct hlist_node node_by_ext_port;
+	struct hlist_node node_by_int_src;
+
+};
+#endif
+
+struct tuple_list {
+	struct nf_conntrack_tuple tuple_original;
+	struct nf_conntrack_tuple tuple_reply;
+	struct list_head list;
+};
+
+/* fullcone specific data structures end */
+
+// NOTE: declaration listed here must use EXPORT_SYMBOL_*
+
+unsigned int nf_nat_fullcone_ipv4(struct sk_buff *skb, unsigned int hooknum,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				  struct nf_nat_range2 *range,
+#else
+				  struct nf_nat_range *range,
+#endif
+				  const struct net_device *out);
+
+unsigned int nf_nat_fullcone_ipv6(struct sk_buff *skb, unsigned int hooknum,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				  struct nf_nat_range2 *range,
+#else
+				  struct nf_nat_range *range,
+#endif
+				  const struct net_device *out);
+
+void nf_nat_fullcone_handle_dying_tuples(void);
+void nf_nat_fullcone_destroy_mappings(void);
+void nf_nat_fullcone_dying_tuple_list_add(struct list_head *new_dying);
+
+/*
+ * For [FUTURE] usage
+ * 
+ * from https://elixir.bootlin.com/linux/v5.15.32/source/net/netfilter/xt_nat.c#L37
+static void xt_nat_convert_range(struct nf_nat_range2 *dst,
+				 const struct nf_nat_ipv4_range *src)
+{
+	memset(&dst->min_addr, 0, sizeof(dst->min_addr));
+	memset(&dst->max_addr, 0, sizeof(dst->max_addr));
+	// base_proto is nf_nat_range2 specific
+	memset(&dst->base_proto, 0, sizeof(dst->base_proto));
+
+	dst->flags	 = src->flags;
+	dst->min_addr.ip = src->min_ip;
+	dst->max_addr.ip = src->max_ip;
+	dst->min_proto	 = src->min;
+	dst->max_proto	 = src->max;
+}
+ * 
+ */
+
+#endif /*_NF_NAT_FULLCONE_H_ */
diff --git a/package/kernel/nft-fullcone/src/nft_ext_fullcone.c b/package/kernel/nft-fullcone/src/nft_ext_fullcone.c
new file mode 100644
index 0000000..c28947a
--- /dev/null
+++ b/package/kernel/nft-fullcone/src/nft_ext_fullcone.c
@@ -0,0 +1,458 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Nftables NAT extension: fullcone expression support
+ *
+ * Copyright (c) 2018 Chion Tang <tech@chionlab.moe>
+ *   Original xt_FULLCONENAT and related iptables extension author
+ * Copyright (c) 2019-2022 GitHub/llccd Twitter/@gNodeB
+ *   Added IPv6 support for xt_FULLCONENAT and ip6tables extension
+ *   Ported to recent kernel versions
+ * Copyright (c) 2022 Syrone Wong <wong.syrone@gmail.com>
+ *   Massively rewrite the whole module, split the original code into library and nftables 'fullcone' expression module
+ */
+#define pr_fmt(fmt) "fullcone " KBUILD_MODNAME ": " fmt
+#define NF_FULLCONE_WORKQUEUE_NAME "fullcone " KBUILD_MODNAME ": wq"
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/netlink.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter/nf_tables.h>
+#include <net/netfilter/nf_tables.h>
+#include <net/netfilter/nf_nat.h>
+
+#include <linux/workqueue.h>
+
+#include "nf_nat_fullcone.h"
+
+static void nft_fullcone_set_regs(const struct nft_expr *expr, const struct nft_regs *regs,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				  struct nf_nat_range2 *range);
+#else
+				  struct nf_nat_range *range);
+#endif
+
+#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
+struct notifier_block ct_event_notifier;
+#else
+struct nf_ct_event_notifier ct_event_notifier;
+#endif
+static DEFINE_MUTEX(nf_ct_net_event_lock);
+int ct_event_notifier_registered = 0;
+
+int module_refer_count = 0;
+
+static void gc_worker(struct work_struct *work);
+static struct workqueue_struct *wq __read_mostly = NULL;
+static DECLARE_DELAYED_WORK(gc_worker_wk, gc_worker);
+
+static void gc_worker(struct work_struct *work)
+{
+	nf_nat_fullcone_handle_dying_tuples();
+}
+
+struct nft_fullcone {
+	u32 flags;
+	u8 sreg_proto_min;
+	u8 sreg_proto_max;
+};
+
+static const struct nla_policy nft_fullcone_policy[NFTA_FULLCONE_MAX + 1] = {
+	[NFTA_FULLCONE_FLAGS] = {.type = NLA_U32 },
+	[NFTA_FULLCONE_REG_PROTO_MIN] = {.type = NLA_U32 },
+	[NFTA_FULLCONE_REG_PROTO_MAX] = {.type = NLA_U32 },
+};
+
+/* conntrack destroy event callback function */
+#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
+static int ct_event_cb(struct notifier_block *this, unsigned long events, void *ptr)
+{
+	struct nf_ct_event *item = ptr;
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
+static int ct_event_cb(unsigned int events, const struct nf_ct_event *item)
+{
+#else
+static int ct_event_cb(unsigned int events, struct nf_ct_event *item)
+{
+#endif
+	struct nf_conn *ct;
+	struct nf_conntrack_tuple *ct_tuple_reply, *ct_tuple_original;
+	uint8_t protonum;
+	struct tuple_list *dying_tuple_item;
+
+	ct = item->ct;
+	/* we handle only conntrack destroy events */
+	if (ct == NULL || !(events & (1 << IPCT_DESTROY))) {
+		return 0;
+	}
+
+	ct_tuple_original = &(ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple);
+
+	ct_tuple_reply = &(ct->tuplehash[IP_CT_DIR_REPLY].tuple);
+
+	protonum = (ct_tuple_original->dst).protonum;
+	if (protonum != IPPROTO_UDP) {
+		return 0;
+	}
+
+	dying_tuple_item = kmalloc(sizeof(struct tuple_list), GFP_ATOMIC);
+
+	if (dying_tuple_item == NULL) {
+		pr_debug("warning: ct_event_cb(): kmalloc failed.\n");
+		return 0;
+	}
+
+	memcpy(&(dying_tuple_item->tuple_original), ct_tuple_original, sizeof(struct nf_conntrack_tuple));
+	memcpy(&(dying_tuple_item->tuple_reply), ct_tuple_reply, sizeof(struct nf_conntrack_tuple));
+
+	nf_nat_fullcone_dying_tuple_list_add(&(dying_tuple_item->list));
+
+	if (wq != NULL)
+		queue_delayed_work(wq, &gc_worker_wk, msecs_to_jiffies(100));
+
+	return 0;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0) && !defined(CONFIG_NF_CONNTRACK_CHAIN_EVENTS)
+static int exp_event_cb(unsigned int events, const struct nf_exp_event *item)
+{
+	return 0;
+}
+#endif
+
+static int nft_fullcone_validate(const struct nft_ctx *ctx, const struct nft_expr *expr, const struct nft_data **data)
+{
+	int err;
+
+	err = nft_chain_validate_dependency(ctx->chain, NFT_CHAIN_T_NAT);
+	if (err < 0)
+		return err;
+
+	// TODO: check hooks
+	return nft_chain_validate_hooks(ctx->chain, (1 << NF_INET_PRE_ROUTING) | (1 << NF_INET_POST_ROUTING));
+}
+
+static int nft_fullcone_init(const struct nft_ctx *ctx, const struct nft_expr *expr, const struct nlattr *const tb[])
+{
+	int err;
+	int register_ct_notifier_ret = 0;
+
+	err = nf_ct_netns_get(ctx->net, ctx->family);
+
+	mutex_lock(&nf_ct_net_event_lock);
+
+	module_refer_count++;
+
+	pr_debug("nft_fullcone_init(): module_refer_count is now %d\n", module_refer_count);
+
+	if (module_refer_count == 1) {
+#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
+		ct_event_notifier.notifier_call = ct_event_cb;
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
+		ct_event_notifier.ct_event = ct_event_cb;
+		ct_event_notifier.exp_event = exp_event_cb;
+#else
+		ct_event_notifier.fcn = ct_event_cb;
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0) && !defined(CONFIG_NF_CONNTRACK_CHAIN_EVENTS)
+		if (!READ_ONCE(ctx->net->ct.nf_conntrack_event_cb)) {
+			nf_conntrack_register_notifier(ctx->net, &ct_event_notifier);
+		}
+#else
+		register_ct_notifier_ret = nf_conntrack_register_notifier(ctx->net, &ct_event_notifier);
+#endif
+
+		if (register_ct_notifier_ret) {
+			/* non-zero means failure */
+			pr_warn("failed to register a conntrack notifier. Disable active GC for mappings.\n");
+		} else {
+			ct_event_notifier_registered = 1;
+			pr_debug("nft_fullcone_init(): ct_event_notifier registered\n");
+		}
+
+	}
+
+	mutex_unlock(&nf_ct_net_event_lock);
+
+	return err;
+}
+
+static int nft_fullcone_dump(struct sk_buff *skb, const struct nft_expr *expr)
+{
+	const struct nft_fullcone *priv = nft_expr_priv(expr);
+
+	if (priv->flags != 0 && nla_put_be32(skb, NFTA_FULLCONE_FLAGS, htonl(priv->flags)))
+		goto nla_put_failure;
+
+	if (priv->sreg_proto_min) {
+		if (nft_dump_register(skb, NFTA_FULLCONE_REG_PROTO_MIN,
+				      priv->sreg_proto_min) ||
+		    nft_dump_register(skb, NFTA_FULLCONE_REG_PROTO_MAX, priv->sreg_proto_max))
+			goto nla_put_failure;
+	}
+
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+
+/* nft_fullcone_set_regs sets nft_regs from nft_expr fullcone specific private data */
+static void nft_fullcone_set_regs(const struct nft_expr *expr, const struct nft_regs *regs,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+				  struct nf_nat_range2 *range
+#else
+				  struct nf_nat_range *range
+#endif
+    )
+{
+	// private data connected via nft_expr_type.ops <==> nft_expr_ops.type
+	// private data type from nft_expr_type.{policy,maxattr,ops}
+	// private data size from nft_expr_ops.size
+	struct nft_fullcone *priv = nft_expr_priv(expr);
+	range->flags = priv->flags;
+	if (priv->sreg_proto_min) {
+		range->min_proto.all = (__force __be16)
+		    nft_reg_load16(&regs->data[priv->sreg_proto_min]);
+		range->max_proto.all = (__force __be16)
+		    nft_reg_load16(&regs->data[priv->sreg_proto_max]);
+	}
+}
+
+static void nft_fullcone_ipv4_eval(const struct nft_expr *expr, struct nft_regs *regs, const struct nft_pktinfo *pkt)
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+	struct nf_nat_range2 range;
+#else
+	struct nf_nat_range range;
+#endif
+
+	memset(&range, 0, sizeof(range));
+	nft_fullcone_set_regs(expr, regs, &range);
+	regs->verdict.code = nf_nat_fullcone_ipv4(pkt->skb, nft_hook(pkt), &range, nft_out(pkt));
+}
+
+static void nft_fullcone_common_destory(const struct nft_ctx *ctx)
+{
+	mutex_lock(&nf_ct_net_event_lock);
+
+	module_refer_count--;
+
+	pr_debug("nft_fullcone_common_destory(): module_refer_count is now %d\n", module_refer_count);
+
+	if (module_refer_count == 0) {
+		if (ct_event_notifier_registered) {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0) && !defined(CONFIG_NF_CONNTRACK_CHAIN_EVENTS)
+			nf_conntrack_unregister_notifier(ctx->net);
+#else
+			nf_conntrack_unregister_notifier(ctx->net, &ct_event_notifier);
+#endif
+			ct_event_notifier_registered = 0;
+
+			pr_debug("nft_fullcone_common_destory(): ct_event_notifier unregistered\n");
+
+		}
+	}
+
+	mutex_unlock(&nf_ct_net_event_lock);
+}
+
+static void nft_fullcone_ipv4_destroy(const struct nft_ctx *ctx, const struct nft_expr *expr)
+{
+	nft_fullcone_common_destory(ctx);
+	nf_ct_netns_put(ctx->net, NFPROTO_IPV4);
+}
+
+static struct nft_expr_type nft_fullcone_ipv4_type;
+static const struct nft_expr_ops nft_fullcone_ipv4_ops = {
+	.type = &nft_fullcone_ipv4_type,
+	.size = NFT_EXPR_SIZE(sizeof(struct nft_fullcone)),
+	.eval = nft_fullcone_ipv4_eval,
+	.init = nft_fullcone_init,
+	.destroy = nft_fullcone_ipv4_destroy,
+	.dump = nft_fullcone_dump,
+	.validate = nft_fullcone_validate,
+};
+
+static struct nft_expr_type nft_fullcone_ipv4_type __read_mostly = {
+	.family = NFPROTO_IPV4,
+	.name = "fullcone",
+	.ops = &nft_fullcone_ipv4_ops,
+	.policy = nft_fullcone_policy,
+	.maxattr = NFTA_FULLCONE_MAX,
+	.owner = THIS_MODULE,
+};
+
+#ifdef CONFIG_NF_TABLES_IPV6
+static void nft_fullcone_ipv6_eval(const struct nft_expr *expr, struct nft_regs *regs, const struct nft_pktinfo *pkt)
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 18, 0)
+	struct nf_nat_range2 range;
+#else
+	struct nf_nat_range range;
+#endif
+
+	memset(&range, 0, sizeof(range));
+	nft_fullcone_set_regs(expr, regs, &range);
+	regs->verdict.code = nf_nat_fullcone_ipv6(pkt->skb, nft_hook(pkt), &range, nft_out(pkt));
+}
+
+static void nft_fullcone_ipv6_destroy(const struct nft_ctx *ctx, const struct nft_expr *expr)
+{
+	nft_fullcone_common_destory(ctx);
+	nf_ct_netns_put(ctx->net, NFPROTO_IPV6);
+}
+
+static struct nft_expr_type nft_fullcone_ipv6_type;
+static const struct nft_expr_ops nft_fullcone_ipv6_ops = {
+	.type = &nft_fullcone_ipv6_type,
+	.size = NFT_EXPR_SIZE(sizeof(struct nft_fullcone)),
+	.eval = nft_fullcone_ipv6_eval,
+	.init = nft_fullcone_init,
+	.destroy = nft_fullcone_ipv6_destroy,
+	.dump = nft_fullcone_dump,
+	.validate = nft_fullcone_validate,
+};
+
+static struct nft_expr_type nft_fullcone_ipv6_type __read_mostly = {
+	.family = NFPROTO_IPV6,
+	.name = "fullcone",
+	.ops = &nft_fullcone_ipv6_ops,
+	.policy = nft_fullcone_policy,
+	.maxattr = NFTA_FULLCONE_MAX,
+	.owner = THIS_MODULE,
+};
+
+static int __init nft_fullcone_module_init_ipv6(void)
+{
+	return nft_register_expr(&nft_fullcone_ipv6_type);
+}
+
+static void nft_fullcone_module_exit_ipv6(void)
+{
+	nft_unregister_expr(&nft_fullcone_ipv6_type);
+}
+#else
+static inline int nft_fullcone_module_init_ipv6(void)
+{
+	return 0;
+}
+
+static inline void nft_fullcone_module_exit_ipv6(void)
+{
+}
+#endif
+
+#ifdef CONFIG_NF_TABLES_INET
+static void nft_fullcone_inet_eval(const struct nft_expr *expr, struct nft_regs *regs, const struct nft_pktinfo *pkt)
+{
+	switch (nft_pf(pkt)) {
+	case NFPROTO_IPV4:
+		return nft_fullcone_ipv4_eval(expr, regs, pkt);
+	case NFPROTO_IPV6:
+		return nft_fullcone_ipv6_eval(expr, regs, pkt);
+	}
+
+	WARN_ON_ONCE(1);
+}
+
+static void nft_fullcone_inet_destroy(const struct nft_ctx *ctx, const struct nft_expr *expr)
+{
+	nft_fullcone_common_destory(ctx);
+	nf_ct_netns_put(ctx->net, NFPROTO_INET);
+}
+
+static struct nft_expr_type nft_fullcone_inet_type;
+static const struct nft_expr_ops nft_fullcone_inet_ops = {
+	.type = &nft_fullcone_inet_type,
+	.size = NFT_EXPR_SIZE(sizeof(struct nft_fullcone)),
+	.eval = nft_fullcone_inet_eval,
+	.init = nft_fullcone_init,
+	.destroy = nft_fullcone_inet_destroy,
+	.dump = nft_fullcone_dump,
+	.validate = nft_fullcone_validate,
+};
+
+static struct nft_expr_type nft_fullcone_inet_type __read_mostly = {
+	.family = NFPROTO_INET,
+	.name = "fullcone",
+	.ops = &nft_fullcone_inet_ops,
+	.policy = nft_fullcone_policy,
+	.maxattr = NFTA_FULLCONE_MAX,
+	.owner = THIS_MODULE,
+};
+
+static int __init nft_fullcone_module_init_inet(void)
+{
+	return nft_register_expr(&nft_fullcone_inet_type);
+}
+
+static void nft_fullcone_module_exit_inet(void)
+{
+	nft_unregister_expr(&nft_fullcone_inet_type);
+}
+#else
+static inline int nft_fullcone_module_init_inet(void)
+{
+	return 0;
+}
+
+static inline void nft_fullcone_module_exit_inet(void)
+{
+}
+#endif
+
+static int __init nft_fullcone_module_init(void)
+{
+	int ret;
+
+	ret = nft_fullcone_module_init_ipv6();
+	if (ret < 0)
+		return ret;
+
+	ret = nft_fullcone_module_init_inet();
+	if (ret < 0) {
+		nft_fullcone_module_exit_ipv6();
+		return ret;
+	}
+
+	ret = nft_register_expr(&nft_fullcone_ipv4_type);
+	if (ret < 0) {
+		nft_fullcone_module_exit_inet();
+		nft_fullcone_module_exit_ipv6();
+		return ret;
+	}
+
+	wq = create_singlethread_workqueue(NF_FULLCONE_WORKQUEUE_NAME);
+	if (wq == NULL) {
+		pr_err("failed to create workqueue %s\n", NF_FULLCONE_WORKQUEUE_NAME);
+	}
+
+	return ret;
+}
+
+static void __exit nft_fullcone_module_exit(void)
+{
+	nft_fullcone_module_exit_ipv6();
+	nft_fullcone_module_exit_inet();
+	nft_unregister_expr(&nft_fullcone_ipv4_type);
+
+	if (wq) {
+		cancel_delayed_work_sync(&gc_worker_wk);
+		flush_workqueue(wq);
+		destroy_workqueue(wq);
+	}
+
+	nf_nat_fullcone_handle_dying_tuples();
+	nf_nat_fullcone_destroy_mappings();
+}
+
+module_init(nft_fullcone_module_init);
+module_exit(nft_fullcone_module_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Syrone Wong <wong.syrone@gmail.com>");
+MODULE_ALIAS_NFT_EXPR("fullcone");
+MODULE_DESCRIPTION("Netfilter nftables fullcone expression support of RFC3489 full cone NAT");
diff --git a/package/libs/libnftnl/Makefile b/package/libs/libnftnl/Makefile
index 37835b4..5342ac2 100644
--- a/package/libs/libnftnl/Makefile
+++ b/package/libs/libnftnl/Makefile
@@ -8,17 +8,18 @@
 include $(TOPDIR)/rules.mk
 
 PKG_NAME:=libnftnl
-PKG_VERSION:=1.2.1
-PKG_RELEASE:=$(AUTORELEASE)
+PKG_CPE_ID:=cpe:/a:netfilter:libnftnl
+PKG_VERSION:=1.2.4
+PKG_RELEASE:=1-fullcone
 
 PKG_SOURCE:=$(PKG_NAME)-$(PKG_VERSION).tar.bz2
 PKG_SOURCE_URL:=https://netfilter.org/projects/$(PKG_NAME)/files
-PKG_HASH:=7508a5c414fab13e3cb3ce8262d0ce4f02c1590a8e4f8628ab497b5b4585937c
+PKG_HASH:=c0fe233be4cdfd703e7d5977ef8eb63fcbf1d0052b6044e1b23d47ca3562477f
 
 PKG_MAINTAINER:=Steven Barth <steven@midlink.org>
 PKG_LICENSE:=GPL-2.0-or-later
 PKG_LICENSE_FILES:=COPYING
-
+PKG_FIXUP:=autoreconf
 PKG_INSTALL:=1
 PKG_BUILD_PARALLEL:=1
 
diff --git a/package/libs/libnftnl/patches/999-01-libnftnl-add-fullcone-expression-support.patch b/package/libs/libnftnl/patches/999-01-libnftnl-add-fullcone-expression-support.patch
new file mode 100644
index 0000000..0e8b349
--- /dev/null
+++ b/package/libs/libnftnl/patches/999-01-libnftnl-add-fullcone-expression-support.patch
@@ -0,0 +1,254 @@
+From 6c39f04febd7cfdbd474233379416babcd0fc341 Mon Sep 17 00:00:00 2001
+From: Syrone Wong <wong.syrone@gmail.com>
+Date: Fri, 8 Apr 2022 23:52:11 +0800
+Subject: [PATCH] libnftnl: add fullcone expression support
+
+Signed-off-by: Syrone Wong <wong.syrone@gmail.com>
+---
+ include/libnftnl/expr.h             |   6 +
+ include/linux/netfilter/nf_tables.h |  16 +++
+ src/Makefile.am                     |   1 +
+ src/expr/fullcone.c                 | 167 ++++++++++++++++++++++++++++
+ src/expr_ops.c                      |   2 +
+ 5 files changed, 192 insertions(+)
+ create mode 100644 src/expr/fullcone.c
+
+--- a/include/libnftnl/expr.h
++++ b/include/libnftnl/expr.h
+@@ -245,6 +245,12 @@ enum {
+ };
+ 
+ enum {
++	NFTNL_EXPR_FULLCONE_FLAGS		= NFTNL_EXPR_BASE,
++	NFTNL_EXPR_FULLCONE_REG_PROTO_MIN,
++	NFTNL_EXPR_FULLCONE_REG_PROTO_MAX,
++};
++
++enum {
+ 	NFTNL_EXPR_REDIR_REG_PROTO_MIN	= NFTNL_EXPR_BASE,
+ 	NFTNL_EXPR_REDIR_REG_PROTO_MAX,
+ 	NFTNL_EXPR_REDIR_FLAGS,
+--- a/include/linux/netfilter/nf_tables.h
++++ b/include/linux/netfilter/nf_tables.h
+@@ -1434,6 +1434,22 @@ enum nft_masq_attributes {
+ #define NFTA_MASQ_MAX		(__NFTA_MASQ_MAX - 1)
+ 
+ /**
++ * enum nft_fullcone_attributes - nf_tables fullcone expression attributes
++ *
++ * @NFTA_FULLCONE_FLAGS: NAT flags (see NF_NAT_RANGE_* in linux/netfilter/nf_nat.h) (NLA_U32)
++ * @NFTA_FULLCONE_REG_PROTO_MIN: source register of proto range start (NLA_U32: nft_registers)
++ * @NFTA_FULLCONE_REG_PROTO_MAX: source register of proto range end (NLA_U32: nft_registers)
++ */
++enum nft_fullcone_attributes {
++	NFTA_FULLCONE_UNSPEC,
++	NFTA_FULLCONE_FLAGS,
++	NFTA_FULLCONE_REG_PROTO_MIN,
++	NFTA_FULLCONE_REG_PROTO_MAX,
++	__NFTA_FULLCONE_MAX
++};
++#define NFTA_FULLCONE_MAX		(__NFTA_FULLCONE_MAX - 1)
++
++/**
+  * enum nft_redir_attributes - nf_tables redirect expression netlink attributes
+  *
+  * @NFTA_REDIR_REG_PROTO_MIN: source register of proto range start (NLA_U32: nft_registers)
+--- a/src/Makefile.am
++++ b/src/Makefile.am
+@@ -54,6 +54,7 @@ libnftnl_la_SOURCES = utils.c		\
+ 		      expr/target.c	\
+ 		      expr/tunnel.c	\
+ 		      expr/masq.c	\
++		      expr/fullcone.c	\
+ 		      expr/redir.c	\
+ 		      expr/hash.c	\
+ 		      expr/socket.c	\
+--- /dev/null
++++ b/src/expr/fullcone.c
+@@ -0,0 +1,168 @@
++/*
++ * (C) 2022 wongsyrone
++ *
++ * This program is free software; you can redistribute it and/or modify
++ * it under the terms of the GNU General Public License as published
++ * by the Free Software Foundation; either version 2 of the License, or
++ * (at your option) any later version.
++ */
++
++#include <stdio.h>
++#include <stdint.h>
++#include <arpa/inet.h>
++#include <errno.h>
++#include <inttypes.h>
++
++#include <linux/netfilter/nf_tables.h>
++
++#include "internal.h"
++#include <libmnl/libmnl.h>
++#include <libnftnl/expr.h>
++#include <libnftnl/rule.h>
++
++struct nftnl_expr_fullcone {
++	uint32_t		flags;
++	enum nft_registers	sreg_proto_min;
++	enum nft_registers	sreg_proto_max;
++};
++
++static int
++nftnl_expr_fullcone_set(struct nftnl_expr *e, uint16_t type,
++		       const void *data, uint32_t data_len)
++{
++	struct nftnl_expr_fullcone *fullcone = nftnl_expr_data(e);
++
++	switch (type) {
++	case NFTNL_EXPR_FULLCONE_FLAGS:
++		memcpy(&fullcone->flags, data, sizeof(fullcone->flags));
++		break;
++	case NFTNL_EXPR_FULLCONE_REG_PROTO_MIN:
++		memcpy(&fullcone->sreg_proto_min, data, sizeof(fullcone->sreg_proto_min));
++		break;
++	case NFTNL_EXPR_FULLCONE_REG_PROTO_MAX:
++		memcpy(&fullcone->sreg_proto_max, data, sizeof(fullcone->sreg_proto_max));
++		break;
++	default:
++		return -1;
++	}
++	return 0;
++}
++
++static const void *
++nftnl_expr_fullcone_get(const struct nftnl_expr *e, uint16_t type,
++		       uint32_t *data_len)
++{
++	struct nftnl_expr_fullcone *fullcone = nftnl_expr_data(e);
++
++	switch (type) {
++	case NFTNL_EXPR_FULLCONE_FLAGS:
++		*data_len = sizeof(fullcone->flags);
++		return &fullcone->flags;
++	case NFTNL_EXPR_FULLCONE_REG_PROTO_MIN:
++		*data_len = sizeof(fullcone->sreg_proto_min);
++		return &fullcone->sreg_proto_min;
++	case NFTNL_EXPR_FULLCONE_REG_PROTO_MAX:
++		*data_len = sizeof(fullcone->sreg_proto_max);
++		return &fullcone->sreg_proto_max;
++	}
++	return NULL;
++}
++
++static int nftnl_expr_fullcone_cb(const struct nlattr *attr, void *data)
++{
++	const struct nlattr **tb = data;
++	int type = mnl_attr_get_type(attr);
++
++	if (mnl_attr_type_valid(attr, NFTA_FULLCONE_MAX) < 0)
++		return MNL_CB_OK;
++
++	switch (type) {
++	case NFTA_FULLCONE_REG_PROTO_MIN:
++	case NFTA_FULLCONE_REG_PROTO_MAX:
++	case NFTA_FULLCONE_FLAGS:
++		if (mnl_attr_validate(attr, MNL_TYPE_U32) < 0)
++			abi_breakage();
++		break;
++	}
++
++	tb[type] = attr;
++	return MNL_CB_OK;
++}
++
++static void
++nftnl_expr_fullcone_build(struct nlmsghdr *nlh, const struct nftnl_expr *e)
++{
++	struct nftnl_expr_fullcone *fullcone = nftnl_expr_data(e);
++
++	if (e->flags & (1 << NFTNL_EXPR_FULLCONE_FLAGS))
++		mnl_attr_put_u32(nlh, NFTA_FULLCONE_FLAGS, htobe32(fullcone->flags));
++	if (e->flags & (1 << NFTNL_EXPR_FULLCONE_REG_PROTO_MIN))
++		mnl_attr_put_u32(nlh, NFTA_FULLCONE_REG_PROTO_MIN,
++				 htobe32(fullcone->sreg_proto_min));
++	if (e->flags & (1 << NFTNL_EXPR_FULLCONE_REG_PROTO_MAX))
++		mnl_attr_put_u32(nlh, NFTA_FULLCONE_REG_PROTO_MAX,
++				 htobe32(fullcone->sreg_proto_max));
++}
++
++static int
++nftnl_expr_fullcone_parse(struct nftnl_expr *e, struct nlattr *attr)
++{
++	struct nftnl_expr_fullcone *fullcone = nftnl_expr_data(e);
++	struct nlattr *tb[NFTA_FULLCONE_MAX+1] = {};
++
++	if (mnl_attr_parse_nested(attr, nftnl_expr_fullcone_cb, tb) < 0)
++		return -1;
++
++	if (tb[NFTA_FULLCONE_FLAGS]) {
++		fullcone->flags = be32toh(mnl_attr_get_u32(tb[NFTA_FULLCONE_FLAGS]));
++		e->flags |= (1 << NFTNL_EXPR_FULLCONE_FLAGS);
++        }
++	if (tb[NFTA_FULLCONE_REG_PROTO_MIN]) {
++		fullcone->sreg_proto_min =
++			be32toh(mnl_attr_get_u32(tb[NFTA_FULLCONE_REG_PROTO_MIN]));
++		e->flags |= (1 << NFTNL_EXPR_FULLCONE_REG_PROTO_MIN);
++	}
++	if (tb[NFTA_FULLCONE_REG_PROTO_MAX]) {
++		fullcone->sreg_proto_max =
++			be32toh(mnl_attr_get_u32(tb[NFTA_FULLCONE_REG_PROTO_MAX]));
++		e->flags |= (1 << NFTNL_EXPR_FULLCONE_REG_PROTO_MAX);
++	}
++
++	return 0;
++}
++
++static int nftnl_expr_fullcone_snprintf(char *buf, size_t remain,
++				    uint32_t flags, const struct nftnl_expr *e)
++{
++	struct nftnl_expr_fullcone *fullcone = nftnl_expr_data(e);
++	int offset = 0, ret = 0;
++
++	if (e->flags & (1 << NFTNL_EXPR_FULLCONE_REG_PROTO_MIN)) {
++		ret = snprintf(buf + offset, remain, "proto_min reg %u ",
++			       fullcone->sreg_proto_min);
++		SNPRINTF_BUFFER_SIZE(ret, remain, offset);
++	}
++	if (e->flags & (1 << NFTNL_EXPR_FULLCONE_REG_PROTO_MAX)) {
++		ret = snprintf(buf + offset, remain, "proto_max reg %u ",
++			       fullcone->sreg_proto_max);
++		SNPRINTF_BUFFER_SIZE(ret, remain, offset);
++	}
++	if (e->flags & (1 << NFTNL_EXPR_FULLCONE_FLAGS)) {
++		ret = snprintf(buf + offset, remain, "flags 0x%x ", fullcone->flags);
++		SNPRINTF_BUFFER_SIZE(ret, remain, offset);
++	}
++
++	return offset;
++}
++
++struct expr_ops expr_ops_fullcone = {
++	.name		= "fullcone",
++	.alloc_len	= sizeof(struct nftnl_expr_fullcone),
++	.max_attr	= NFTA_FULLCONE_MAX,
++	.set		= nftnl_expr_fullcone_set,
++	.get		= nftnl_expr_fullcone_get,
++	.parse		= nftnl_expr_fullcone_parse,
++	.build		= nftnl_expr_fullcone_build,
++	.output		= nftnl_expr_fullcone_snprintf,
++};
++
+--- a/src/expr_ops.c
++++ b/src/expr_ops.c
+@@ -19,6 +19,7 @@ extern struct expr_ops expr_ops_limit;
+ extern struct expr_ops expr_ops_log;
+ extern struct expr_ops expr_ops_lookup;
+ extern struct expr_ops expr_ops_masq;
++extern struct expr_ops expr_ops_fullcone;
+ extern struct expr_ops expr_ops_match;
+ extern struct expr_ops expr_ops_meta;
+ extern struct expr_ops expr_ops_ng;
+@@ -63,6 +64,7 @@ static struct expr_ops *expr_ops[] = {
+ 	&expr_ops_log,
+ 	&expr_ops_lookup,
+ 	&expr_ops_masq,
++	&expr_ops_fullcone,
+ 	&expr_ops_match,
+ 	&expr_ops_meta,
+ 	&expr_ops_ng,
diff --git a/package/network/config/firewall4/Makefile b/package/network/config/firewall4/Makefile
index 58ed133..effe2cd 100644
--- a/package/network/config/firewall4/Makefile
+++ b/package/network/config/firewall4/Makefile
@@ -5,13 +5,13 @@
 include $(TOPDIR)/rules.mk
 
 PKG_NAME:=firewall4
-PKG_RELEASE:=$(AUTORELEASE)
+PKG_RELEASE:=1-fullcone
 
 PKG_SOURCE_PROTO:=git
 PKG_SOURCE_URL=$(PROJECT_GIT)/project/firewall4.git
-PKG_SOURCE_DATE:=2022-10-14
-PKG_SOURCE_VERSION:=4fbf6d75a4a9e523d1848a28d8a3ea095e870195
-PKG_MIRROR_HASH:=d8ffb01baf0c8412962aaaf504ad05387f3fef5bd709f7b7840ddd4e8311b4bb
+PKG_SOURCE_DATE:=2022-10-18
+PKG_SOURCE_VERSION:=7ae5e14bbd7265cc67ec870c3bb0c8e197bb7ca9
+PKG_MIRROR_HASH:=ce190e526df915df65b40aa24fadf2a1b5badc57ab4e564d5f44575b11d18e26
 PKG_MAINTAINER:=Jo-Philipp Wich <jo@mein.io>
 PKG_LICENSE:=ISC
 
diff --git a/package/network/config/firewall4/patches/999-01-firewall4-add-fullcone-support.patch b/package/network/config/firewall4/patches/999-01-firewall4-add-fullcone-support.patch
new file mode 100644
index 0000000..492e047
--- /dev/null
+++ b/package/network/config/firewall4/patches/999-01-firewall4-add-fullcone-support.patch
@@ -0,0 +1,239 @@
+From aa3b56e289fba7425e649a608c333622ffd9c367 Mon Sep 17 00:00:00 2001
+From: Syrone Wong <wong.syrone@gmail.com>
+Date: Sat, 9 Apr 2022 13:24:19 +0800
+Subject: [PATCH] firewall4: add fullcone support
+
+fullcone is drop-in replacement of masq for non-udp traffic
+
+add runtime fullcone rule check, disable it globally if fullcone expr is
+invalid
+
+defaults.fullcone is the global switch, while zone.fullcone4 and
+zone.fullcone6 are switches for IPv4 and IPv6 respectively, most
+IPv6 traffic do NOT need this FullCone NAT functionality.
+---
+ root/etc/config/firewall                      |  2 +
+ root/usr/share/firewall4/templates/ruleset.uc | 11 ++++-
+ .../firewall4/templates/zone-fullcone.uc      |  4 ++
+ root/usr/share/ucode/fw4.uc                   | 44 ++++++++++++++++++-
+ 4 files changed, 58 insertions(+), 3 deletions(-)
+ create mode 100644 root/usr/share/firewall4/templates/zone-fullcone.uc
+
+--- a/root/etc/config/firewall
++++ b/root/etc/config/firewall
+@@ -5,6 +5,7 @@ config defaults
+ 	option forward		REJECT
+ # Uncomment this line to disable ipv6 rules
+ #	option disable_ipv6	1
++	option fullcone '1'
+ 
+ config zone
+ 	option name		lan
+@@ -20,6 +21,8 @@ config zone
+ 	option input		REJECT
+ 	option output		ACCEPT
+ 	option forward		REJECT
++	option fullcone4 '1'
++	option fullcone6 '1'
+ 	option masq		1
+ 	option mtu_fix		1
+ 
+--- /dev/null
++++ b/root/usr/share/firewall4/templates/zone-fullcone.uc
+@@ -0,0 +1,4 @@
++{# /usr/share/firewall4/templates/zone-fullcone.uc #}
++		meta nfproto {{ fw4.nfproto(family) }} fullcone comment "!fw4: Handle {{
++		zone.name
++}} {{ fw4.nfproto(family, true) }} fullcone NAT {{ direction }} traffic"
+--- a/root/usr/share/ucode/fw4.uc
++++ b/root/usr/share/ucode/fw4.uc
+@@ -1,3 +1,5 @@
++// /usr/share/ucode/fw4.uc
++
+ const fs = require("fs");
+ const uci = require("uci");
+ const ubus = require("ubus");
+@@ -428,6 +430,25 @@ function nft_try_hw_offload(devices) {
+ 	return (rc == 0);
+ }
+ 
++function nft_try_fullcone() {
++	let nft_test =
++		'add table inet fw4-fullcone-test; ' +
++		'add chain inet fw4-fullcone-test dstnat { ' +
++			'type nat hook prerouting priority -100; policy accept; ' +
++			'fullcone; ' +
++		'}; ' +
++		'add chain inet fw4-fullcone-test srcnat { ' +
++			'type nat hook postrouting priority -100; policy accept; ' +
++			'fullcone; ' +
++		'}; ';
++	let cmd = sprintf("/usr/sbin/nft -c '%s' 2>/dev/null", replace(nft_test, "'", "'\\''"));
++	let ok = system(cmd) == 0;
++	if (!ok) {
++		warn("nft_try_fullcone: cmd "+ cmd + "\n");
++	}
++	return ok;
++}
++
+ 
+ return {
+ 	read_kernel_version: function() {
+@@ -778,6 +799,18 @@ return {
+ 			warn(`[!] ${msg}\n`);
+ 	},
+ 
++	myinfo: function(fmt, ...args) {
++		if (getenv("QUIET"))
++			return;
++
++		let msg = sprintf(fmt, ...args);
++
++		if (getenv("TTY"))
++			warn(`\033[32m${msg}\033[m\n`);
++		else
++			warn(`[I] ${msg}\n`);
++	},
++
+ 	get: function(sid, opt) {
+ 		return this.cursor.get("firewall", sid, opt);
+ 	},
+@@ -959,6 +992,21 @@ return {
+ 		}
+ 	},
+ 
++	myinfo_section: function(s, msg) {
++		if (s[".name"]) {
++			if (s.name)
++				this.myinfo("Section %s (%s) %s", this.section_id(s[".name"]), s.name, msg);
++			else
++				this.myinfo("Section %s %s", this.section_id(s[".name"]), msg);
++		}
++		else {
++			if (s.name)
++				this.myinfo("ubus %s (%s) %s", s.type || "rule", s.name, msg);
++			else
++				this.myinfo("ubus %s %s", s.type || "rule", msg);
++		}
++	},
++
+ 	parse_policy: function(val) {
+ 		return this.parse_enum(val, [
+ 			"accept",
+@@ -1398,6 +1446,7 @@ return {
+ 			"dnat",
+ 			"snat",
+ 			"masquerade",
++			"fullcone",
+ 			"accept",
+ 			"reject",
+ 			"drop"
+@@ -1865,6 +1914,7 @@ return {
+ 		}
+ 
+ 		let defs = this.parse_options(data, {
++			fullcone: [ "bool", "0" ],
+ 			input: [ "policy", "drop" ],
+ 			output: [ "policy", "drop" ],
+ 			forward: [ "policy", "drop" ],
+@@ -1899,6 +1949,11 @@ return {
+ 
+ 		delete defs.syn_flood;
+ 
++		if (!nft_try_fullcone()) {
++			delete defs.fullcone;
++			warn("nft_try_fullcone failed, disable fullcone globally\n");
++		}
++
+ 		this.state.defaults = defs;
+ 	},
+ 
+@@ -1923,6 +1978,8 @@ return {
+ 			masq_dest: [ "network", null, PARSE_LIST ],
+ 
+ 			masq6: [ "bool" ],
++			fullcone4: [ "bool", "0" ],
++			fullcone6: [ "bool", "0" ],
+ 
+ 			extra: [ "string", null, UNSUPPORTED ],
+ 			extra_src: [ "string", null, UNSUPPORTED ],
+@@ -1955,6 +2012,18 @@ return {
+ 			}
+ 		}
+ 
++		if (this.state.defaults && !this.state.defaults.fullcone) {
++			this.warn_section(data, "fullcone in defaults not enabled, ignore zone fullcone settings");
++			zone.fullcone4 = false;
++			zone.fullcone6 = false;
++		}
++		if (zone.fullcone4) {
++			this.myinfo_section(data, "IPv4 fullcone enabled for zone '" + zone.name + "'");
++		}
++		if (zone.fullcone6) {
++			this.myinfo_section(data, "IPv6 fullcone enabled for zone '" + zone.name + "'");
++		}
++
+ 		if (zone.mtu_fix && this.kernel < 0x040a0000) {
+ 			this.warn_section(data, "option 'mtu_fix' requires kernel 4.10 or later");
+ 			return;
+@@ -2124,10 +2193,15 @@ return {
+ 		zone.related_subnets = related_subnets;
+ 		zone.related_physdevs = related_physdevs;
+ 
++		if (zone.fullcone4 || zone.fullcone6) {
++			zone.dflags.snat = true;
++			zone.dflags.dnat = true;
++		}
++
+ 		if (zone.masq || zone.masq6)
+ 			zone.dflags.snat = true;
+ 
+-		if ((zone.auto_helper && !(zone.masq || zone.masq6)) || length(zone.helper)) {
++		if ((zone.auto_helper && !(zone.masq || zone.masq6 || zone.fullcone4 || zone.fullcone6)) || length(zone.helper)) {
+ 			zone.dflags.helper = true;
+ 
+ 			for (let helper in (length(zone.helper) ? zone.helper : this.state.helpers)) {
+--- a/root/usr/share/firewall4/templates/ruleset.uc
++++ b/root/usr/share/firewall4/templates/ruleset.uc
+@@ -310,6 +310,12 @@ table inet fw4 {
+ {%   for (let redirect in fw4.redirects(`dstnat_${zone.name}`)): %}
+ 		{%+ include("redirect.uc", { fw4, redirect }) %}
+ {%   endfor %}
++{%   if (zone.fullcone4): %}
++		{%+ include("zone-fullcone.uc", { fw4, zone, family: 4, direction: "dstnat" }) %}
++{%   endif %}
++{%   if (zone.fullcone6): %}
++		{%+ include("zone-fullcone.uc", { fw4, zone, family: 6, direction: "dstnat" }) %}
++{%   endif %}
+ {%   fw4.includes('chain-append', `dstnat_${zone.name}`) %}
+ 	}
+ 
+@@ -320,20 +326,26 @@ table inet fw4 {
+ {%   for (let redirect in fw4.redirects(`srcnat_${zone.name}`)): %}
+ 		{%+ include("redirect.uc", { fw4, redirect }) %}
+ {%   endfor %}
+-{%   if (zone.masq): %}
++{%   if (zone.masq && !zone.fullcone4): %}
+ {%    for (let saddrs in zone.masq4_src_subnets): %}
+ {%     for (let daddrs in zone.masq4_dest_subnets): %}
+ 		{%+ include("zone-masq.uc", { fw4, zone, family: 4, saddrs, daddrs }) %}
+ {%     endfor %}
+ {%    endfor %}
+ {%   endif %}
+-{%   if (zone.masq6): %}
++{%   if (zone.masq6 && !zone.fullcone6): %}
+ {%    for (let saddrs in zone.masq6_src_subnets): %}
+ {%     for (let daddrs in zone.masq6_dest_subnets): %}
+ 		{%+ include("zone-masq.uc", { fw4, zone, family: 6, saddrs, daddrs }) %}
+ {%     endfor %}
+ {%    endfor %}
+ {%   endif %}
++{%   if (zone.fullcone4): %}
++		{%+ include("zone-fullcone.uc", { fw4, zone, family: 4, direction: "srcnat" }) %}
++{%   endif %}
++{%   if (zone.fullcone6): %}
++		{%+ include("zone-fullcone.uc", { fw4, zone, family: 6, direction: "srcnat" }) %}
++{%   endif %}
+ {%   fw4.includes('chain-append', `srcnat_${zone.name}`) %}
+ 	}
+ 
diff --git a/package/network/utils/nftables/Makefile b/package/network/utils/nftables/Makefile
index b9e896a..0af8dee 100644
--- a/package/network/utils/nftables/Makefile
+++ b/package/network/utils/nftables/Makefile
@@ -7,14 +7,16 @@
 include $(TOPDIR)/rules.mk
 
 PKG_NAME:=nftables
-PKG_VERSION:=1.0.2
-PKG_RELEASE:=2.1
+PKG_VERSION:=1.0.5
+PKG_RELEASE:=1-fullcone
 
 PKG_SOURCE:=$(PKG_NAME)-$(PKG_VERSION).tar.bz2
 PKG_SOURCE_URL:=https://netfilter.org/projects/$(PKG_NAME)/files
-PKG_HASH:=0b28a36ffcf4567b841de7bd3f37918b1fed27859eb48bdec51e1f7a83954c02
+PKG_HASH:=8d1b4b18393af43698d10baa25d2b9b6397969beecac7816c35dd0714e4de50a
+
 PKG_MAINTAINER:=
 PKG_LICENSE:=GPL-2.0
+PKG_LICENSE_FILES:=COPYING
 
 PKG_FIXUP:=autoreconf
 PKG_INSTALL:=1
diff --git a/package/network/utils/nftables/patches/0001-fix-nft.patch b/package/network/utils/nftables/patches/0001-fix-nft.patch
new file mode 100644
index 0000000..2138e25
--- /dev/null
+++ b/package/network/utils/nftables/patches/0001-fix-nft.patch
@@ -0,0 +1,23 @@
+'rule inet dscpclassify dscp_match  meta l4proto { udp }  th dport { 3478 }  th sport { 3478-3497, 16384-16387 } goto ct_set_ef'
+works with 'nft add', but not 'nft insert', the latter yields: "BUG: unhandled op 4".
+
+Fixes: 81e36530fcac ("src: replace interval segment tree overlap and automerge")
+Signed-off-by: Florian Westphal <fw@strlen.de>
+---
+ src/evaluate.c | 1 +
+ 1 file changed, 1 insertion(+)
+
+diff --git a/src/evaluate.c b/src/evaluate.c
+index d9c9ca28a53a..edebd7bcd8ab 100644
+--- a/src/evaluate.c
++++ b/src/evaluate.c
+@@ -1520,6 +1520,7 @@ static int interval_set_eval(struct eval_ctx *ctx, struct set *set,
+ 	switch (ctx->cmd->op) {
+ 	case CMD_CREATE:
+ 	case CMD_ADD:
++	case CMD_INSERT:
+ 		if (set->automerge) {
+ 			ret = set_automerge(ctx->msgs, ctx->cmd, set, init,
+ 					    ctx->nft->debug_mask);
+-- 
+2.35.1
diff --git a/package/network/utils/nftables/patches/0001-meta-don-t-use-non-POSIX-formats-in-strptime.patch b/package/network/utils/nftables/patches/0001-meta-don-t-use-non-POSIX-formats-in-strptime.patch
deleted file mode 100644
index 12cac8c..0000000
--- a/package/network/utils/nftables/patches/0001-meta-don-t-use-non-POSIX-formats-in-strptime.patch
+++ /dev/null
@@ -1,44 +0,0 @@
-From 1af8aabccd65e11caa397c4706353075f623cd01 Mon Sep 17 00:00:00 2001
-From: Jo-Philipp Wich <jo@mein.io>
-Date: Mon, 8 Aug 2022 23:57:03 +0200
-Subject: [PATCH] meta: don't use non-POSIX formats in strptime()
-
-The current strptime() invocations in meta.c use the `%F` format which
-is not specified by POSIX and thus unimplemented by some libc flavors
-such as musl libc.
-
-Replace all occurrences of `%F` with an equivalent `%Y-%m-%d` format
-in order to be able to properly parse user supplied dates in such
-environments.
-
-Signed-off-by: Jo-Philipp Wich <jo@mein.io>
----
- src/meta.c | 8 ++++----
- 1 file changed, 4 insertions(+), 4 deletions(-)
-
---- a/src/meta.c
-+++ b/src/meta.c
-@@ -399,7 +399,7 @@ static void date_type_print(const struct
- 		tstamp += cur_tm->tm_gmtoff;
- 
- 	if ((tm = gmtime((time_t *) &tstamp)) != NULL &&
--	     strftime(timestr, sizeof(timestr) - 1, "%F %T", tm))
-+	     strftime(timestr, sizeof(timestr) - 1, "%Y-%m-%d %T", tm))
- 		nft_print(octx, "\"%s\"", timestr);
- 	else
- 		nft_print(octx, "Error converting timestamp to printed time");
-@@ -412,11 +412,11 @@ static time_t parse_iso_date(const char
- 
- 	memset(&tm, 0, sizeof(struct tm));
- 
--	if (strptime(sym, "%F %T", &tm))
-+	if (strptime(sym, "%Y-%m-%d %T", &tm))
- 		goto success;
--	if (strptime(sym, "%F %R", &tm))
-+	if (strptime(sym, "%Y-%m-%d %R", &tm))
- 		goto success;
--	if (strptime(sym, "%F", &tm))
-+	if (strptime(sym, "%Y-%m-%d", &tm))
- 		goto success;
- 
- 	return -1;
diff --git a/package/network/utils/nftables/patches/001-examples-compile-with-make-check.patch b/package/network/utils/nftables/patches/001-examples-compile-with-make-check.patch
deleted file mode 100644
index 6a4430d..0000000
--- a/package/network/utils/nftables/patches/001-examples-compile-with-make-check.patch
+++ /dev/null
@@ -1,29 +0,0 @@
-From 18a08fb7f0443f8bde83393bd6f69e23a04246b3 Mon Sep 17 00:00:00 2001
-From: Pablo Neira Ayuso <pablo@netfilter.org>
-Date: Tue, 22 Feb 2022 00:56:36 +0100
-Subject: examples: compile with `make check' and add AM_CPPFLAGS
-
-Compile examples via `make check' like libnftnl does. Use AM_CPPFLAGS to
-specify local headers via -I.
-
-Unfortunately, `make distcheck' did not catch this compile time error in
-my system, since it was using the nftables/libnftables.h file of the
-previous nftables release.
-
-Fixes: 5b364657a35f ("build: missing SUBIRS update")
-Fixes: caf2a6ad2d22 ("examples: add libnftables example program")
-Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
----
- examples/Makefile.am | 4 +++-
- 1 file changed, 3 insertions(+), 1 deletion(-)
-
---- a/examples/Makefile.am
-+++ b/examples/Makefile.am
-@@ -1,4 +1,6 @@
--noinst_PROGRAMS	= nft-buffer		\
-+check_PROGRAMS	= nft-buffer		\
- 		  nft-json-file
- 
-+AM_CPPFLAGS = -I$(top_srcdir)/include
-+
- LDADD = $(top_builddir)/src/libnftables.la
diff --git a/package/network/utils/nftables/patches/999-01-nftables-add-fullcone-expression-support.patch b/package/network/utils/nftables/patches/999-01-nftables-add-fullcone-expression-support.patch
new file mode 100644
index 0000000..ae6cacf
--- /dev/null
+++ b/package/network/utils/nftables/patches/999-01-nftables-add-fullcone-expression-support.patch
@@ -0,0 +1,209 @@
+From b6e3ad4c0bb845a05d73ef1be46ffb73517d1565 Mon Sep 17 00:00:00 2001
+From: Syrone Wong <wong.syrone@gmail.com>
+Date: Sat, 9 Apr 2022 00:38:51 +0800
+Subject: [PATCH] nftables: add fullcone expression support
+
+Signed-off-by: Syrone Wong <wong.syrone@gmail.com>
+---
+ include/linux/netfilter/nf_tables.h | 16 ++++++++++
+ include/statement.h                 |  1 +
+ src/netlink_delinearize.c           | 48 +++++++++++++++++++++++++++++
+ src/netlink_linearize.c             |  7 +++++
+ src/parser_bison.y                  | 28 +++++++++++++++--
+ src/scanner.l                       |  1 +
+ src/statement.c                     |  1 +
+ 7 files changed, 100 insertions(+), 2 deletions(-)
+
+--- a/include/linux/netfilter/nf_tables.h
++++ b/include/linux/netfilter/nf_tables.h
+@@ -1410,6 +1410,22 @@ enum nft_masq_attributes {
+ #define NFTA_MASQ_MAX		(__NFTA_MASQ_MAX - 1)
+ 
+ /**
++ * enum nft_fullcone_attributes - nf_tables fullcone expression attributes
++ *
++ * @NFTA_FULLCONE_FLAGS: NAT flags (see NF_NAT_RANGE_* in linux/netfilter/nf_nat.h) (NLA_U32)
++ * @NFTA_FULLCONE_REG_PROTO_MIN: source register of proto range start (NLA_U32: nft_registers)
++ * @NFTA_FULLCONE_REG_PROTO_MAX: source register of proto range end (NLA_U32: nft_registers)
++ */
++enum nft_fullcone_attributes {
++	NFTA_FULLCONE_UNSPEC,
++	NFTA_FULLCONE_FLAGS,
++	NFTA_FULLCONE_REG_PROTO_MIN,
++	NFTA_FULLCONE_REG_PROTO_MAX,
++	__NFTA_FULLCONE_MAX
++};
++#define NFTA_FULLCONE_MAX		(__NFTA_FULLCONE_MAX - 1)
++
++/**
+  * enum nft_redir_attributes - nf_tables redirect expression netlink attributes
+  *
+  * @NFTA_REDIR_REG_PROTO_MIN: source register of proto range start (NLA_U32: nft_registers)
+--- a/include/statement.h
++++ b/include/statement.h
+@@ -122,6 +122,7 @@ enum nft_nat_etypes {
+ 	__NFT_NAT_SNAT = NFT_NAT_SNAT,
+ 	__NFT_NAT_DNAT = NFT_NAT_DNAT,
+ 	NFT_NAT_MASQ,
++	NFT_NAT_FULLCONE,
+ 	NFT_NAT_REDIR,
+ };
+ 
+--- a/src/netlink_delinearize.c
++++ b/src/netlink_delinearize.c
+@@ -1370,6 +1370,53 @@ out_err:
+ 	stmt_free(stmt);
+ }
+ 
++static void netlink_parse_fullcone(struct netlink_parse_ctx *ctx,
++			       const struct location *loc,
++			       const struct nftnl_expr *nle)
++{
++	enum nft_registers reg1, reg2;
++	struct expr *proto;
++	struct stmt *stmt;
++	uint32_t flags = 0;
++
++	if (nftnl_expr_is_set(nle, NFTNL_EXPR_FULLCONE_FLAGS))
++		flags = nftnl_expr_get_u32(nle, NFTNL_EXPR_FULLCONE_FLAGS);
++
++	stmt = nat_stmt_alloc(loc, NFT_NAT_FULLCONE);
++	stmt->nat.flags = flags;
++
++	reg1 = netlink_parse_register(nle, NFTNL_EXPR_FULLCONE_REG_PROTO_MIN);
++	if (reg1) {
++		proto = netlink_get_register(ctx, loc, reg1);
++		if (proto == NULL) {
++			netlink_error(ctx, loc,
++				      "fullcone statement has no proto expression");
++			goto out_err;
++		}
++		expr_set_type(proto, &inet_service_type, BYTEORDER_BIG_ENDIAN);
++		stmt->nat.proto = proto;
++	}
++
++	reg2 = netlink_parse_register(nle, NFTNL_EXPR_FULLCONE_REG_PROTO_MAX);
++	if (reg2 && reg2 != reg1) {
++		proto = netlink_get_register(ctx, loc, reg2);
++		if (proto == NULL) {
++			netlink_error(ctx, loc,
++				      "fullcone statement has no proto expression");
++			goto out_err;
++		}
++		expr_set_type(proto, &inet_service_type, BYTEORDER_BIG_ENDIAN);
++		if (stmt->nat.proto != NULL)
++			proto = range_expr_alloc(loc, stmt->nat.proto, proto);
++		stmt->nat.proto = proto;
++	}
++
++	ctx->stmt = stmt;
++	return;
++out_err:
++	stmt_free(stmt);
++}
++
+ static void netlink_parse_redir(struct netlink_parse_ctx *ctx,
+ 				const struct location *loc,
+ 				const struct nftnl_expr *nle)
+@@ -1788,6 +1835,7 @@ static const struct expr_handler netlink
+ 	{ .name = "tproxy",	.parse = netlink_parse_tproxy },
+ 	{ .name = "notrack",	.parse = netlink_parse_notrack },
+ 	{ .name = "masq",	.parse = netlink_parse_masq },
++	{ .name = "fullcone",	.parse = netlink_parse_fullcone },
+ 	{ .name = "redir",	.parse = netlink_parse_redir },
+ 	{ .name = "dup",	.parse = netlink_parse_dup },
+ 	{ .name = "queue",	.parse = netlink_parse_queue },
+--- a/src/netlink_linearize.c
++++ b/src/netlink_linearize.c
+@@ -1140,6 +1140,13 @@ static void netlink_gen_nat_stmt(struct
+ 		nftnl_reg_pmin = NFTNL_EXPR_MASQ_REG_PROTO_MIN;
+ 		nftnl_reg_pmax = NFTNL_EXPR_MASQ_REG_PROTO_MAX;
+ 		break;
++	case NFT_NAT_FULLCONE:
++		nle = alloc_nft_expr("fullcone");
++
++		nftnl_flag_attr = NFTNL_EXPR_FULLCONE_FLAGS;
++		nftnl_reg_pmin = NFTNL_EXPR_FULLCONE_REG_PROTO_MIN;
++		nftnl_reg_pmax = NFTNL_EXPR_FULLCONE_REG_PROTO_MAX;
++		break;
+ 	case NFT_NAT_REDIR:
+ 		nle = alloc_nft_expr("redir");
+ 
+--- a/src/parser_bison.y
++++ b/src/parser_bison.y
+@@ -571,6 +571,7 @@ int nft_lex(void *, void *, void *);
+ %token SNAT			"snat"
+ %token DNAT			"dnat"
+ %token MASQUERADE		"masquerade"
++%token FULLCONE		"fullcone"
+ %token REDIRECT			"redirect"
+ %token RANDOM			"random"
+ %token FULLY_RANDOM		"fully-random"
+@@ -703,8 +704,8 @@ int nft_lex(void *, void *, void *);
+ %type <val>			limit_burst_pkts limit_burst_bytes limit_mode limit_bytes time_unit quota_mode
+ %type <stmt>			reject_stmt reject_stmt_alloc
+ %destructor { stmt_free($$); }	reject_stmt reject_stmt_alloc
+-%type <stmt>			nat_stmt nat_stmt_alloc masq_stmt masq_stmt_alloc redir_stmt redir_stmt_alloc
+-%destructor { stmt_free($$); }	nat_stmt nat_stmt_alloc masq_stmt masq_stmt_alloc redir_stmt redir_stmt_alloc
++%type <stmt>			nat_stmt nat_stmt_alloc masq_stmt masq_stmt_alloc fullcone_stmt fullcone_stmt_alloc redir_stmt redir_stmt_alloc
++%destructor { stmt_free($$); }	nat_stmt nat_stmt_alloc masq_stmt masq_stmt_alloc fullcone_stmt fullcone_stmt_alloc redir_stmt redir_stmt_alloc
+ %type <val>			nf_nat_flags nf_nat_flag offset_opt
+ %type <stmt>			tproxy_stmt
+ %destructor { stmt_free($$); }	tproxy_stmt
+@@ -2852,6 +2853,7 @@ stmt			:	verdict_stmt
+ 			|	queue_stmt
+ 			|	ct_stmt
+ 			|	masq_stmt	close_scope_nat
++			|	fullcone_stmt	close_scope_nat
+ 			|	redir_stmt	close_scope_nat
+ 			|	dup_stmt	close_scope_dup
+ 			|	fwd_stmt	close_scope_fwd
+@@ -3741,6 +3743,28 @@ masq_stmt_args		:	TO 	COLON	stmt_expr
+ 			{
+ 				$<stmt>0->nat.proto = $3;
+ 			}
++			|	TO 	COLON	stmt_expr	nf_nat_flags
++			{
++				$<stmt>0->nat.proto = $3;
++				$<stmt>0->nat.flags = $4;
++			}
++			|	nf_nat_flags
++			{
++				$<stmt>0->nat.flags = $1;
++			}
++			;
++
++fullcone_stmt		:	fullcone_stmt_alloc		fullcone_stmt_args
++			|	fullcone_stmt_alloc
++			;
++
++fullcone_stmt_alloc		:	FULLCONE	{ $$ = nat_stmt_alloc(&@$, NFT_NAT_FULLCONE); }
++			;
++
++fullcone_stmt_args		:	TO 	COLON	stmt_expr
++			{
++				$<stmt>0->nat.proto = $3;
++			}
+ 			|	TO 	COLON	stmt_expr	nf_nat_flags
+ 			{
+ 				$<stmt>0->nat.proto = $3;
+--- a/src/scanner.l
++++ b/src/scanner.l
+@@ -447,6 +447,7 @@ addrstring	({macaddr}|{ip4addr}|{ip6addr
+ "snat"			{ scanner_push_start_cond(yyscanner, SCANSTATE_STMT_NAT); return SNAT; }
+ "dnat"			{ scanner_push_start_cond(yyscanner, SCANSTATE_STMT_NAT); return DNAT; }
+ "masquerade"		{ scanner_push_start_cond(yyscanner, SCANSTATE_STMT_NAT); return MASQUERADE; }
++"fullcone"		{ scanner_push_start_cond(yyscanner, SCANSTATE_STMT_NAT); return FULLCONE; }
+ "redirect"		{ scanner_push_start_cond(yyscanner, SCANSTATE_STMT_NAT); return REDIRECT; }
+ "random"		{ return RANDOM; }
+ <SCANSTATE_STMT_NAT>{
+--- a/src/statement.c
++++ b/src/statement.c
+@@ -650,6 +650,7 @@ const char *nat_etype2str(enum nft_nat_e
+ 		[NFT_NAT_SNAT]	= "snat",
+ 		[NFT_NAT_DNAT]	= "dnat",
+ 		[NFT_NAT_MASQ]	= "masquerade",
++		[NFT_NAT_FULLCONE] = "fullcone",
+ 		[NFT_NAT_REDIR]	= "redirect",
+ 	};
+ 
